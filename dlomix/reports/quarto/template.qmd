---
title: "TITLE_HERE"
format:
  html:
    code-fold: FOLD_CODE_FLAG
    page-layout: full
  pdf:
    echo: false
format-links: false
jupyter: python3
---

# Model information
The following section shows information about the model. The table below contains information about the models' layers.

* Model: MODEL_NAME
* Total parameters: TOTAL_PARAMS
* Trainable parameters: TRAINABLE_PARAMS
* Non-trainable parameters: NT_PARAMS

LAYER_TABLE
{{< pagebreak >}}

DATA_SECTION_PLACEHOLDER

TRAIN_SECTION_PLACEHOLDER

VAL_SECTION_PLACEHOLDER

# Train-Validation metrics per epoch
The following section shows the training metrics in comparision with the validation metrics. The training loss is a metric used to assess how well a model fits the training data. In contrast the validation
loss assesses the performance of the model on previously unseen data. Plotting both curves in the same plot provides a
quick way of diagnosing the model for overfitting or underfitting.
All used metrics are added by default.

![Plots of training metrics vs. validation metrics](TV_PLOTS_PATH)
{{< pagebreak >}}

# Residuals
This section shows a histogram of the residuals of the model. Residuals are the difference between the actual values and
the predicted values of the test set. A histogram of those residuals offers a way of assessing the models performance.

![Histogram of model's residuals](RESIDUALS_PLOT_PATH)
{{< pagebreak >}}

# Density
This section shows the density plot. A better explanation of the density plot is yet to be done.

![Density plot](DENSITY_PLOT_PATH)


# R2 score
The R2 of given predictions is R2_SCORE_VALUE. The R2 score is a metric that is calculated using scikit learns's function
r2_score. It evaluates the performance of the model on the test set and compares the predicted values with the actual values.
The best possible score is 1.0. The lower the score the worse the model's prediction.
