{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../bmpc_shared_scripts/prepare_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cmnfs/home/f.kapitza/miniconda3/envs/dlomix/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Avaliable feature extractors are (use the key of the following dict and pass it to features_to_extract in the Dataset Class):\n",
      "{\n",
      "   \"atom_count\": \"Atom count of PTM.\",\n",
      "   \"delta_mass\": \"Delta mass of PTM.\",\n",
      "   \"mod_gain\": \"Gain of atoms due to PTM.\",\n",
      "   \"mod_loss\": \"Loss of atoms due to PTM.\",\n",
      "   \"red_smiles\": \"Reduced SMILES representation of PTM.\"\n",
      "}.\n",
      "When writing your own feature extractor, you can either\n",
      "    (1) use the FeatureExtractor class or\n",
      "    (2) write a function that can be mapped to the Hugging Face dataset.\n",
      "In both cases, you can access the parsed sequence information from the dataset using the following keys, which all provide python lists:\n",
      "    - _parsed_sequence: parsed sequence\n",
      "    - _n_term_mods: N-terminal modifications\n",
      "    - _c_term_mods: C-terminal modifications\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-19 11:54:46.398514: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-19 11:54:46.398571: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-19 11:54:46.400101: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-19 11:54:46.408113: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-19 11:54:48.467707: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from dlomix.data.fragment_ion_intensity import FragmentIonIntensityDataset\n",
    "from dlomix.constants import PTMS_ALPHABET\n",
    "import tensorflow as tf\n",
    "from pyarrow import parquet as pq\n",
    "from dlomix.losses import masked_spectral_distance\n",
    "from get_updated_alphabet import get_modification\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-19 11:54:51.427349: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "2024-07-19 11:54:51.427426: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:129] retrieving CUDA diagnostic information for host: minotaur.exbio.wzw.tum.de\n",
      "2024-07-19 11:54:51.427435: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:136] hostname: minotaur.exbio.wzw.tum.de\n",
      "2024-07-19 11:54:51.427582: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:159] libcuda reported version is: 550.90.7\n",
      "2024-07-19 11:54:51.427622: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:163] kernel reported version is: 550.90.7\n",
      "2024-07-19 11:54:51.427629: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:241] kernel version seems to match DSO: 550.90.7\n"
     ]
    }
   ],
   "source": [
    "# load a model\n",
    "MODEL_DIR = '/cmnfs/proj/bmpc_dlomix/models/baseline_models/noptm_baseline_full_bs1024_unmod_extended/'\n",
    "RUN_NAME = '7ef3360f-2349-46c0-a905-01187d4899e2'\n",
    "model = tf.keras.models.load_model(MODEL_DIR + RUN_NAME + '.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_parquet_path = '/cmnfs/proj/bmpc_dlomix/datasets/parquet/noptm_baseline_small_train.parquet'\n",
    "ion_types = ['y', 'b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if intensities column in parquet file\n",
    "inference_only = True\n",
    "col_names = pq.read_schema(small_parquet_path).names\n",
    "if 'intensities_raw' in col_names:\n",
    "    inference_only = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 11.00it/s]\n"
     ]
    }
   ],
   "source": [
    "# get all tokens present in the dataset\n",
    "file = pq.ParquetFile(small_parquet_path)\n",
    "dataset_tokens = set()\n",
    "for batch in tqdm(file.iter_batches()):\n",
    "    for cur_seq in batch['modified_sequence']:\n",
    "        cur_mods = get_modification(str(cur_seq))\n",
    "        dataset_tokens |= set(cur_mods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No tokens unknown to the model appear in the dataset!\n"
     ]
    }
   ],
   "source": [
    "# get the model alphabet and compare with the tokens from the dataset\n",
    "# if new modifications are present -> need new embedding layer\n",
    "model_tokens = set(model.alphabet.keys())\n",
    "difference = dataset_tokens - model_tokens\n",
    "if not difference:\n",
    "    print('No tokens unknown to the model appear in the dataset!')\n",
    "    new_alphabet = model.alphabet\n",
    "else:\n",
    "    print(f'These tokens appear in the dataset, but are not known to the model {difference}')\n",
    "    print('A new embedding layer is necessary.')\n",
    "    old_alphabet = model.alphabet\n",
    "    new_alphabet = old_alphabet.update({k: i for i, k in enumerate(difference, start=len(model.alphabet) + 1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new ion types detected. Output layer can stay the same.\n"
     ]
    }
   ],
   "source": [
    "# check for the ion types -> if ion types contain other than the b and y ions -> new output layer is necessary\n",
    "number_of_ions = len(ion_types)\n",
    "if any([ion_type in ['c', 'z', 'a', 'x'] for ion_type in ion_types]):\n",
    "    if len(number_of_ions) == 2:\n",
    "        print(f'New ion types detected, but only 2 ion types present. -> reinitialize the output layer')\n",
    "    if len(number_of_ions) > 2:\n",
    "        if 'y' in ion_types and 'b' in ion_types:\n",
    "            print('New Ion types in addition to y and b ions detected -> new output layer, but can keep trained weights for y and b ions')\n",
    "else:\n",
    "    print('No new ion types detected. Output layer can stay the same.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mapping SequenceParsingProcessor: 100%|██████████| 6400/6400 [00:00<00:00, 10424.86 examples/s]\n",
      "Mapping SequenceParsingProcessor: 100%|██████████| 1600/1600 [00:00<00:00, 9912.83 examples/s] \n",
      "Mapping SequenceEncodingProcessor: 100%|██████████| 6400/6400 [00:00<00:00, 15803.83 examples/s]\n",
      "Mapping SequenceEncodingProcessor: 100%|██████████| 1600/1600 [00:00<00:00, 10502.73 examples/s]\n",
      "Mapping SequencePaddingProcessor: 100%|██████████| 6400/6400 [00:00<00:00, 17052.17 examples/s]\n",
      "Mapping SequencePaddingProcessor: 100%|██████████| 1600/1600 [00:00<00:00, 12661.72 examples/s]\n",
      "Filter: 100%|██████████| 6400/6400 [00:00<00:00, 326997.42 examples/s]\n",
      "Filter: 100%|██████████| 1600/1600 [00:00<00:00, 71847.19 examples/s]\n",
      "Casting the dataset: 100%|██████████| 6390/6390 [00:01<00:00, 4419.79 examples/s]\n",
      "Casting the dataset: 100%|██████████| 1598/1598 [00:00<00:00, 4469.37 examples/s]\n"
     ]
    }
   ],
   "source": [
    "ds = FragmentIonIntensityDataset(\n",
    "    data_source=small_parquet_path,\n",
    "    data_format='parquet',\n",
    "    inference_only=inference_only,\n",
    "    alphabet=new_alphabet,\n",
    "    encoding_scheme='naive-mods',\n",
    "    model_features=[\"precursor_charge_onehot\", \"collision_energy_aligned_normed\", \"method_nbr\"],\n",
    "    ion_types=['y', 'b', 'z', 'c']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['modified_sequence', 'intensities_raw', 'precursor_charge_onehot', 'collision_energy_aligned_normed', 'method_nbr', '_parsed_sequence', '_n_term_mods', '_c_term_mods'],\n",
       "        num_rows: 6391\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['modified_sequence', 'intensities_raw', 'precursor_charge_onehot', 'collision_energy_aligned_normed', 'method_nbr', '_parsed_sequence', '_n_term_mods', '_c_term_mods'],\n",
       "        num_rows: 1597\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.hf_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y', 'b', 'z', 'c']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.ion_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test the process_dataset function on different use cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../bmpc_shared_scripts/oktoberfest_interface')\n",
    "from oktoberfest_interface import process_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different dataset paths\n",
    "etd_dataset = '/cmnfs/proj/bmpc_dlomix/datasets/parquet/new_ion_types_ETD_support_edited.parquet'\n",
    "inference_only_ds = 'test_inference_only.parquet'\n",
    "single_ptm = '/cmnfs/data/proteomics/Prosit_PTMs/21PTMs/Kmod_Formyl.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model path\n",
    "model_path = '/cmnfs/proj/bmpc_dlomix/models/baseline_models/noptm_baseline_full_bs1024_unmod_extended/7ef3360f-2349-46c0-a905-01187d4899e2.keras'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cmnfs/home/f.kapitza/dlomix/finn_notebooks/../bmpc_shared_scripts/oktoberfest_interface/oktoberfest_interface.py:69: UserWarning: \n",
      "                Number of ions is the same as the loaded model supports, but the ion types are different.\n",
      "                The model probably needs to be refined to achieve a better performance on these new ion types.\n",
      "                \n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start processing the dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mapping SequenceParsingProcessor: 100%|██████████| 6302/6302 [00:00<00:00, 10704.92 examples/s]\n",
      "Mapping SequenceParsingProcessor: 100%|██████████| 1576/1576 [00:00<00:00, 10473.91 examples/s]\n",
      "Mapping SequenceEncodingProcessor: 100%|██████████| 6302/6302 [00:00<00:00, 18409.15 examples/s]\n",
      "Mapping SequenceEncodingProcessor: 100%|██████████| 1576/1576 [00:00<00:00, 12151.23 examples/s]\n",
      "Mapping SequencePaddingProcessor: 100%|██████████| 6302/6302 [00:00<00:00, 19121.32 examples/s]\n",
      "Mapping SequencePaddingProcessor: 100%|██████████| 1576/1576 [00:00<00:00, 13252.84 examples/s]\n",
      "Filter: 100%|██████████| 6302/6302 [00:00<00:00, 354984.54 examples/s]\n",
      "Filter: 100%|██████████| 1576/1576 [00:00<00:00, 155574.93 examples/s]\n",
      "Casting the dataset: 100%|██████████| 6300/6300 [00:01<00:00, 4535.82 examples/s]\n",
      "Casting the dataset: 100%|██████████| 1575/1575 [00:00<00:00, 2930.95 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The available data splits are: train, val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'val'])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds, model = process_dataset(etd_dataset, model_path, ion_types=['z', 'c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start processing the dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 7878 examples [00:00, 190705.20 examples/s]\n",
      "/cmnfs/home/f.kapitza/dlomix/src/dlomix/data/dataset.py:366: UserWarning: \n",
      "                This is a inference only dataset! You can only make predictions with this dataset! Attempting to\n",
      "                train a model with this dataset will result in an error!\n",
      "                \n",
      "  warnings.warn(\n",
      "Mapping SequenceParsingProcessor: 100%|██████████| 7878/7878 [00:00<00:00, 61882.63 examples/s]\n",
      "Mapping SequenceEncodingProcessor: 100%|██████████| 7878/7878 [00:00<00:00, 52750.79 examples/s]\n",
      "Mapping SequencePaddingProcessor: 100%|██████████| 7878/7878 [00:00<00:00, 48444.92 examples/s]\n",
      "Filter: 100%|██████████| 7878/7878 [00:00<00:00, 484888.50 examples/s]\n",
      "Casting the dataset: 100%|██████████| 7875/7875 [00:01<00:00, 6177.81 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The available data splits are: inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ds, model = process_dataset(inference_only_ds, 'unmod_ext', ion_types=['y', 'b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cmnfs/home/f.kapitza/dlomix/finn_notebooks/../bmpc_shared_scripts/oktoberfest_interface/oktoberfest_interface.py:58: UserWarning: \n",
      "            There are new tokens in the dataset, which are not supported by the loaded model.\n",
      "            Either load a different model or transfer learning needs to be done.\n",
      "            \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start processing the dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mapping SequenceParsingProcessor: 100%|██████████| 6839/6839 [00:01<00:00, 6166.51 examples/s]\n",
      "Mapping SequenceParsingProcessor: 100%|██████████| 1710/1710 [00:00<00:00, 7753.03 examples/s] \n",
      "Mapping SequenceEncodingProcessor: 100%|██████████| 6839/6839 [00:00<00:00, 17776.25 examples/s]\n",
      "Mapping SequenceEncodingProcessor: 100%|██████████| 1710/1710 [00:00<00:00, 10453.15 examples/s]\n",
      "Mapping SequencePaddingProcessor: 100%|██████████| 6839/6839 [00:00<00:00, 15557.11 examples/s]\n",
      "Mapping SequencePaddingProcessor: 100%|██████████| 1710/1710 [00:01<00:00, 1686.71 examples/s]\n",
      "Filter: 100%|██████████| 6839/6839 [00:00<00:00, 136080.63 examples/s]\n",
      "Filter: 100%|██████████| 1710/1710 [00:02<00:00, 676.75 examples/s]\n",
      "Casting the dataset: 100%|██████████| 6839/6839 [00:02<00:00, 3092.24 examples/s]\n",
      "Casting the dataset: 100%|██████████| 1710/1710 [00:00<00:00, 3025.42 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The available data splits are: train, val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ds, model = process_dataset(single_ptm, 'unmod_ext', modifications=['K[UNIMOD:1]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlomix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
