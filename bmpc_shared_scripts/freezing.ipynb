{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of Freezing Strategies for Refinement/Transfer Learning\n",
    "This script is for trying out different freezing mechanisms and controls using tensorflow and keras. Goal is to have an easy access function that we can use for further training, refinement and transfer learning for the Prosit Models and ultimately implement in DLOmix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 12:32:15.351367: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-12 12:32:15.351404: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-12 12:32:15.352700: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-12 12:32:15.360056: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-12 12:32:16.972630: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import dlomix\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "import yaml\n",
    "from dlomix.losses import masked_spectral_distance, masked_pearson_correlation_distance\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare stuff for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read the config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"baseline_training/config_files/noptm_baseline_small_bs1024.yaml\"\n",
    "\n",
    "with open(config_path, 'r') as yaml_file:\n",
    "    config = yaml.safe_load(yaml_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load the dataset and the PTM alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/home/students/l.willruth/miniconda3/envs/dlomix/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Avaliable feature extractors are (use the key of the following dict and pass it to features_to_extract in the Dataset Class):\n",
      "{\n",
      "   \"atom_count\": \"Atom count of PTM.\",\n",
      "   \"delta_mass\": \"Delta mass of PTM.\",\n",
      "   \"mod_gain\": \"Gain of atoms due to PTM.\",\n",
      "   \"mod_loss\": \"Loss of atoms due to PTM.\",\n",
      "   \"red_smiles\": \"Reduced SMILES representation of PTM.\"\n",
      "}.\n",
      "When writing your own feature extractor, you can either\n",
      "    (1) use the FeatureExtractor class or\n",
      "    (2) write a function that can be mapped to the Hugging Face dataset.\n",
      "In both cases, you can access the parsed sequence information from the dataset using the following keys, which all provide python lists:\n",
      "    - _parsed_sequence: parsed sequence\n",
      "    - _n_term_mods: N-terminal modifications\n",
      "    - _c_term_mods: C-terminal modifications\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "from dlomix.data import FragmentIonIntensityDataset\n",
    "\n",
    "# from misc import PTMS_ALPHABET\n",
    "from dlomix.constants import PTMS_ALPHABET\n",
    "\n",
    "from dlomix.data import load_processed_dataset\n",
    "dataset = load_processed_dataset(config['dataset']['processed_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Initialize the optimizer and callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 12:32:20.244576: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=config['training']['learning_rate'])\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0.001,\n",
    "    patience=20,\n",
    "    restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlomix.models import PrositIntensityPredictor\n",
    "\n",
    "input_mapping = {\n",
    "        \"SEQUENCE_KEY\": \"modified_sequence\",\n",
    "        \"COLLISION_ENERGY_KEY\": \"collision_energy_aligned_normed\",\n",
    "        \"PRECURSOR_CHARGE_KEY\": \"precursor_charge_onehot\",\n",
    "        \"FRAGMENTATION_TYPE_KEY\": \"method_nbr\",\n",
    "    }\n",
    "\n",
    "meta_data_keys=[\"collision_energy_aligned_normed\", \"precursor_charge_onehot\", \"method_nbr\"]\n",
    "\n",
    "model = PrositIntensityPredictor(\n",
    "    seq_length=config['dataset']['seq_length'],\n",
    "    alphabet=PTMS_ALPHABET,\n",
    "    use_prosit_ptm_features=False,\n",
    "    with_termini=False,\n",
    "    input_keys=input_mapping,\n",
    "    meta_data_keys=meta_data_keys\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=masked_spectral_distance,\n",
    "    metrics=[masked_pearson_correlation_distance]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 25s 2s/step - loss: 0.6835 - masked_pearson_correlation_distance: 0.5837 - val_loss: 0.6672 - val_masked_pearson_correlation_distance: 0.5573\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f5b843d0fa0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    dataset.tensor_train_data,\n",
    "    validation_data=dataset.tensor_val_data,\n",
    "    epochs=config['training']['num_epochs'],\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"prosit_intensity_predictor\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       multiple                  928       \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 30, 512)           1996800   \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   multiple                  4608      \n",
      "                                                                 \n",
      " sequential_2 (Sequential)   (None, 29, 512)           1576806   \n",
      "                                                                 \n",
      " encoder_att (AttentionLaye  multiple                  542       \n",
      " r)                                                              \n",
      "                                                                 \n",
      " sequential_3 (Sequential)   multiple                  0         \n",
      "                                                                 \n",
      " sequential_4 (Sequential)   (None, 174)               3078      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3582762 (13.67 MB)\n",
      "Trainable params: 3582762 (13.67 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freezing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check if weights are correctly assigned to trainable/non-trainable:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers with weigths: 21\n",
      "layers with trainable weigths: 21\n",
      "layers with non-trainable weigths: 0\n"
     ]
    }
   ],
   "source": [
    "print(f'layers with weigths: {len(model.weights)}')\n",
    "print(f'layers with trainable weigths: {len(model.trainable_weights)}')\n",
    "print(f'layers with non-trainable weigths: {len(model.non_trainable_weights)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Freeze the whole model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers with weigths: 21\n",
      "layers with trainable weigths: 0\n",
      "layers with non-trainable weigths: 21\n"
     ]
    }
   ],
   "source": [
    "print(f'layers with weigths: {len(model.weights)}')\n",
    "print(f'layers with trainable weigths: {len(model.trainable_weights)}')\n",
    "print(f'layers with non-trainable weigths: {len(model.non_trainable_weights)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfreeze again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Freeze the model and only keep the first and/or the last layer trainable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to freeze all layers except first and/or last layer\n",
    "def freeze_model(model:dlomix.models.prosit.PrositIntensityPredictor, trainable_first_layer:bool = False, trainable_last_layer:bool = False) -> None:\n",
    "    \n",
    "    # reset everything to trainable, 'model.trainable = False' overshadowes trainable arguments of sublayers\n",
    "    model.trainable = True \n",
    "    \n",
    "    # go through layers and set trainable to False at lowest level so trainable argument is not overshadowed\n",
    "    for lay in model.layers:\n",
    "        try:\n",
    "            for sublay in lay.layers:\n",
    "                sublay.trainable = False\n",
    "        except (AttributeError):\n",
    "            lay.trainable = False\n",
    "\n",
    "    if (trainable_first_layer):\n",
    "        first_layer = model.get_layer(name=\"embedding\")\n",
    "        first_layer.trainable = True\n",
    "\n",
    "    if (trainable_last_layer):\n",
    "        last_layer = model.get_layer(name = \"sequential_4\").get_layer(name = \"time_dense\")\n",
    "        last_layer.trainable = True\n",
    "\n",
    "    # compile the model again to make changes take effect\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=masked_spectral_distance,\n",
    "        metrics=[masked_pearson_correlation_distance]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_trainability(model, sublayers = False):\n",
    "    for lay in model.layers:\n",
    "        if(sublayers):\n",
    "            print()\n",
    "            try:\n",
    "                lay.layers\n",
    "                print(f'Sequential {lay} trainable: {lay.trainable}')\n",
    "                for lay2 in lay.layers:\n",
    "                    print(f'{lay2} trainable: {lay2.trainable}')\n",
    "            except(AttributeError):\n",
    "                print(f'{lay} trainable: {lay.trainable}')\n",
    "        else:\n",
    "            print(f'{lay} trainable: {lay.trainable}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing the function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Freeze all layers except the first layer:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<keras.src.layers.core.embedding.Embedding object at 0x7f5b846589a0> trainable: True\n",
      "\n",
      "Sequential <keras.src.engine.sequential.Sequential object at 0x7f5b8465bbe0> trainable: True\n",
      "<keras.src.layers.rnn.bidirectional.Bidirectional object at 0x7f5b84659690> trainable: False\n",
      "<keras.src.layers.regularization.dropout.Dropout object at 0x7f5b8465ad10> trainable: False\n",
      "<keras.src.layers.rnn.gru.GRU object at 0x7f5b8465afe0> trainable: False\n",
      "<keras.src.layers.regularization.dropout.Dropout object at 0x7f5b8465b910> trainable: False\n",
      "\n",
      "Sequential <keras.src.engine.sequential.Sequential object at 0x7f5b84740a60> trainable: True\n",
      "<keras.src.layers.merging.concatenate.Concatenate object at 0x7f5b8465bc10> trainable: False\n",
      "<keras.src.layers.core.dense.Dense object at 0x7f5b84740400> trainable: False\n",
      "<keras.src.layers.regularization.dropout.Dropout object at 0x7f5b847407f0> trainable: False\n",
      "\n",
      "Sequential <keras.src.engine.sequential.Sequential object at 0x7f5b84741d80> trainable: True\n",
      "<keras.src.layers.rnn.gru.GRU object at 0x7f5b84740df0> trainable: False\n",
      "<keras.src.layers.regularization.dropout.Dropout object at 0x7f5b84741900> trainable: False\n",
      "<dlomix.layers.attention.DecoderAttentionLayer object at 0x7f5b84741bd0> trainable: False\n",
      "\n",
      "<dlomix.layers.attention.AttentionLayer object at 0x7f5b84742140> trainable: False\n",
      "\n",
      "Sequential <keras.src.engine.sequential.Sequential object at 0x7f5b84742aa0> trainable: True\n",
      "<keras.src.layers.merging.multiply.Multiply object at 0x7f5b847426b0> trainable: False\n",
      "<keras.src.layers.reshaping.repeat_vector.RepeatVector object at 0x7f5b84742890> trainable: False\n",
      "\n",
      "Sequential <keras.src.engine.sequential.Sequential object at 0x7f5b84743a30> trainable: True\n",
      "<keras.src.layers.rnn.time_distributed.TimeDistributed object at 0x7f5b84743430> trainable: False\n",
      "<keras.src.layers.activation.leaky_relu.LeakyReLU object at 0x7f5b847435b0> trainable: False\n",
      "<keras.src.layers.reshaping.flatten.Flatten object at 0x7f5b847437c0> trainable: False\n"
     ]
    }
   ],
   "source": [
    "freeze_model(model, trainable_first_layer=True)\n",
    "check_trainability(model, sublayers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Freeze all layers except the last layer:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<keras.src.layers.core.embedding.Embedding object at 0x7f5b846589a0> trainable: False\n",
      "\n",
      "Sequential <keras.src.engine.sequential.Sequential object at 0x7f5b8465bbe0> trainable: True\n",
      "<keras.src.layers.rnn.bidirectional.Bidirectional object at 0x7f5b84659690> trainable: False\n",
      "<keras.src.layers.regularization.dropout.Dropout object at 0x7f5b8465ad10> trainable: False\n",
      "<keras.src.layers.rnn.gru.GRU object at 0x7f5b8465afe0> trainable: False\n",
      "<keras.src.layers.regularization.dropout.Dropout object at 0x7f5b8465b910> trainable: False\n",
      "\n",
      "Sequential <keras.src.engine.sequential.Sequential object at 0x7f5b84740a60> trainable: True\n",
      "<keras.src.layers.merging.concatenate.Concatenate object at 0x7f5b8465bc10> trainable: False\n",
      "<keras.src.layers.core.dense.Dense object at 0x7f5b84740400> trainable: False\n",
      "<keras.src.layers.regularization.dropout.Dropout object at 0x7f5b847407f0> trainable: False\n",
      "\n",
      "Sequential <keras.src.engine.sequential.Sequential object at 0x7f5b84741d80> trainable: True\n",
      "<keras.src.layers.rnn.gru.GRU object at 0x7f5b84740df0> trainable: False\n",
      "<keras.src.layers.regularization.dropout.Dropout object at 0x7f5b84741900> trainable: False\n",
      "<dlomix.layers.attention.DecoderAttentionLayer object at 0x7f5b84741bd0> trainable: False\n",
      "\n",
      "<dlomix.layers.attention.AttentionLayer object at 0x7f5b84742140> trainable: False\n",
      "\n",
      "Sequential <keras.src.engine.sequential.Sequential object at 0x7f5b84742aa0> trainable: True\n",
      "<keras.src.layers.merging.multiply.Multiply object at 0x7f5b847426b0> trainable: False\n",
      "<keras.src.layers.reshaping.repeat_vector.RepeatVector object at 0x7f5b84742890> trainable: False\n",
      "\n",
      "Sequential <keras.src.engine.sequential.Sequential object at 0x7f5b84743a30> trainable: True\n",
      "<keras.src.layers.rnn.time_distributed.TimeDistributed object at 0x7f5b84743430> trainable: True\n",
      "<keras.src.layers.activation.leaky_relu.LeakyReLU object at 0x7f5b847435b0> trainable: False\n",
      "<keras.src.layers.reshaping.flatten.Flatten object at 0x7f5b847437c0> trainable: False\n"
     ]
    }
   ],
   "source": [
    "freeze_model(model, trainable_last_layer=True)\n",
    "check_trainability(model, sublayers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Freeze all layers except the first and the last layer:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<keras.src.layers.core.embedding.Embedding object at 0x7f5b846589a0> trainable: True\n",
      "\n",
      "Sequential <keras.src.engine.sequential.Sequential object at 0x7f5b8465bbe0> trainable: True\n",
      "<keras.src.layers.rnn.bidirectional.Bidirectional object at 0x7f5b84659690> trainable: False\n",
      "<keras.src.layers.regularization.dropout.Dropout object at 0x7f5b8465ad10> trainable: False\n",
      "<keras.src.layers.rnn.gru.GRU object at 0x7f5b8465afe0> trainable: False\n",
      "<keras.src.layers.regularization.dropout.Dropout object at 0x7f5b8465b910> trainable: False\n",
      "\n",
      "Sequential <keras.src.engine.sequential.Sequential object at 0x7f5b84740a60> trainable: True\n",
      "<keras.src.layers.merging.concatenate.Concatenate object at 0x7f5b8465bc10> trainable: False\n",
      "<keras.src.layers.core.dense.Dense object at 0x7f5b84740400> trainable: False\n",
      "<keras.src.layers.regularization.dropout.Dropout object at 0x7f5b847407f0> trainable: False\n",
      "\n",
      "Sequential <keras.src.engine.sequential.Sequential object at 0x7f5b84741d80> trainable: True\n",
      "<keras.src.layers.rnn.gru.GRU object at 0x7f5b84740df0> trainable: False\n",
      "<keras.src.layers.regularization.dropout.Dropout object at 0x7f5b84741900> trainable: False\n",
      "<dlomix.layers.attention.DecoderAttentionLayer object at 0x7f5b84741bd0> trainable: False\n",
      "\n",
      "<dlomix.layers.attention.AttentionLayer object at 0x7f5b84742140> trainable: False\n",
      "\n",
      "Sequential <keras.src.engine.sequential.Sequential object at 0x7f5b84742aa0> trainable: True\n",
      "<keras.src.layers.merging.multiply.Multiply object at 0x7f5b847426b0> trainable: False\n",
      "<keras.src.layers.reshaping.repeat_vector.RepeatVector object at 0x7f5b84742890> trainable: False\n",
      "\n",
      "Sequential <keras.src.engine.sequential.Sequential object at 0x7f5b84743a30> trainable: True\n",
      "<keras.src.layers.rnn.time_distributed.TimeDistributed object at 0x7f5b84743430> trainable: True\n",
      "<keras.src.layers.activation.leaky_relu.LeakyReLU object at 0x7f5b847435b0> trainable: False\n",
      "<keras.src.layers.reshaping.flatten.Flatten object at 0x7f5b847437c0> trainable: False\n"
     ]
    }
   ],
   "source": [
    "freeze_model(model, trainable_first_layer=True, trainable_last_layer=True)\n",
    "check_trainability(model, sublayers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continue Training with frozen layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<keras.src.layers.core.embedding.Embedding object at 0x7f5b846589a0> trainable: True\n",
      "\n",
      "Sequential <keras.src.engine.sequential.Sequential object at 0x7f5b8465bbe0> trainable: True\n",
      "<keras.src.layers.rnn.bidirectional.Bidirectional object at 0x7f5b84659690> trainable: False\n",
      "<keras.src.layers.regularization.dropout.Dropout object at 0x7f5b8465ad10> trainable: False\n",
      "<keras.src.layers.rnn.gru.GRU object at 0x7f5b8465afe0> trainable: False\n",
      "<keras.src.layers.regularization.dropout.Dropout object at 0x7f5b8465b910> trainable: False\n",
      "\n",
      "Sequential <keras.src.engine.sequential.Sequential object at 0x7f5b84740a60> trainable: True\n",
      "<keras.src.layers.merging.concatenate.Concatenate object at 0x7f5b8465bc10> trainable: False\n",
      "<keras.src.layers.core.dense.Dense object at 0x7f5b84740400> trainable: False\n",
      "<keras.src.layers.regularization.dropout.Dropout object at 0x7f5b847407f0> trainable: False\n",
      "\n",
      "Sequential <keras.src.engine.sequential.Sequential object at 0x7f5b84741d80> trainable: True\n",
      "<keras.src.layers.rnn.gru.GRU object at 0x7f5b84740df0> trainable: False\n",
      "<keras.src.layers.regularization.dropout.Dropout object at 0x7f5b84741900> trainable: False\n",
      "<dlomix.layers.attention.DecoderAttentionLayer object at 0x7f5b84741bd0> trainable: False\n",
      "\n",
      "<dlomix.layers.attention.AttentionLayer object at 0x7f5b84742140> trainable: False\n",
      "\n",
      "Sequential <keras.src.engine.sequential.Sequential object at 0x7f5b84742aa0> trainable: True\n",
      "<keras.src.layers.merging.multiply.Multiply object at 0x7f5b847426b0> trainable: False\n",
      "<keras.src.layers.reshaping.repeat_vector.RepeatVector object at 0x7f5b84742890> trainable: False\n",
      "\n",
      "Sequential <keras.src.engine.sequential.Sequential object at 0x7f5b84743a30> trainable: True\n",
      "<keras.src.layers.rnn.time_distributed.TimeDistributed object at 0x7f5b84743430> trainable: True\n",
      "<keras.src.layers.activation.leaky_relu.LeakyReLU object at 0x7f5b847435b0> trainable: False\n",
      "<keras.src.layers.reshaping.flatten.Flatten object at 0x7f5b847437c0> trainable: False\n"
     ]
    }
   ],
   "source": [
    "freeze_model(model, trainable_first_layer=True, trainable_last_layer=True)\n",
    "check_trainability(model, sublayers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_weights = model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 20s 2s/step - loss: 0.6666 - masked_pearson_correlation_distance: 0.5576 - val_loss: 0.6673 - val_masked_pearson_correlation_distance: 0.5566\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f5b283bd030>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train again while only the first layer and the last layer are trainable\n",
    "model.fit(\n",
    "    dataset.tensor_train_data,\n",
    "    validation_data=dataset.tensor_val_data,\n",
    "    epochs=1,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights 0 stayed the same: False\n",
      "weights 1 stayed the same: True\n",
      "weights 2 stayed the same: True\n",
      "weights 3 stayed the same: True\n",
      "weights 4 stayed the same: True\n",
      "weights 5 stayed the same: True\n",
      "weights 6 stayed the same: True\n",
      "weights 7 stayed the same: True\n",
      "weights 8 stayed the same: True\n",
      "weights 9 stayed the same: True\n",
      "weights 10 stayed the same: True\n",
      "weights 11 stayed the same: True\n",
      "weights 12 stayed the same: True\n",
      "weights 13 stayed the same: True\n",
      "weights 14 stayed the same: True\n",
      "weights 15 stayed the same: True\n",
      "weights 16 stayed the same: True\n",
      "weights 17 stayed the same: True\n",
      "weights 18 stayed the same: True\n",
      "weights 19 stayed the same: False\n",
      "weights 20 stayed the same: False\n"
     ]
    }
   ],
   "source": [
    "# check which weights have changed\n",
    "retrained_weights = model.get_weights()\n",
    "for i, w in enumerate(zip(original_weights, retrained_weights)):\n",
    "    print(f'weights {i} stayed the same: {(w[0]==w[1]).all()}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two weight tensors changed for the last layer. Both tensors belong to the last time_dense layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00050617  0.00042338  0.00032402  0.00051246  0.00016971 -0.00047507]\n",
      "512\n",
      "[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n",
      "3078\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_dense (TimeDistribute  (None, 29, 6)             3078      \n",
      " d)                                                              \n",
      "                                                                 \n",
      " activation (LeakyReLU)      (None, 29, 6)             0         \n",
      "                                                                 \n",
      " out (Flatten)               (None, 174)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3078 (12.02 KB)\n",
      "Trainable params: 3078 (12.02 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(retrained_weights[20]) # 6\n",
    "print(len(retrained_weights[19])) # 512\n",
    "print([len(x) for x in retrained_weights[19]]) # 6\n",
    "print(512 * 6 + 6)\n",
    "print(model.get_layer(name=\"sequential_4\").summary())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlomix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
