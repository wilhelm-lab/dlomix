{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of Freezing Strategies for Refinement/Transfer Learning\n",
    "This script is for trying out different freezing mechanisms and controls using tensorflow and keras. Goal is to have some easy access functions that we can use for further training, refinement and transfer learning for the Prosit Models and ultimately implement in DLOmix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 06:56:20.447750: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-12 06:56:20.447927: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-12 06:56:20.756529: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-12 06:56:21.656853: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-12 06:56:33.768658: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import dlomix\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "import yaml\n",
    "from dlomix.losses import masked_spectral_distance, masked_pearson_correlation_distance\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare stuff for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read the config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"baseline_training/config_files/noptm_baseline_small_bs1024.yaml\"\n",
    "\n",
    "with open(config_path, 'r') as yaml_file:\n",
    "    config = yaml.safe_load(yaml_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load the dataset and the PTM alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/home/students/l.willruth/miniconda3/envs/dlomix/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Avaliable feature extractors are (use the key of the following dict and pass it to features_to_extract in the Dataset Class):\n",
      "{\n",
      "   \"atom_count\": \"Atom count of PTM.\",\n",
      "   \"delta_mass\": \"Delta mass of PTM.\",\n",
      "   \"mod_gain\": \"Gain of atoms due to PTM.\",\n",
      "   \"mod_loss\": \"Loss of atoms due to PTM.\",\n",
      "   \"red_smiles\": \"Reduced SMILES representation of PTM.\"\n",
      "}.\n",
      "When writing your own feature extractor, you can either\n",
      "    (1) use the FeatureExtractor class or\n",
      "    (2) write a function that can be mapped to the Hugging Face dataset.\n",
      "In both cases, you can access the parsed sequence information from the dataset using the following keys, which all provide python lists:\n",
      "    - _parsed_sequence: parsed sequence\n",
      "    - _n_term_mods: N-terminal modifications\n",
      "    - _c_term_mods: C-terminal modifications\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "from dlomix.data import FragmentIonIntensityDataset\n",
    "\n",
    "# from misc import PTMS_ALPHABET\n",
    "from dlomix.constants import PTMS_ALPHABET\n",
    "\n",
    "from dlomix.data import load_processed_dataset\n",
    "dataset = load_processed_dataset(config['dataset']['processed_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Initialize the optimizer and callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 06:59:46.085620: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=config['training']['learning_rate'])\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0.001,\n",
    "    patience=20,\n",
    "    restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlomix.models import PrositIntensityPredictor\n",
    "\n",
    "input_mapping = {\n",
    "        \"SEQUENCE_KEY\": \"modified_sequence\",\n",
    "        \"COLLISION_ENERGY_KEY\": \"collision_energy_aligned_normed\",\n",
    "        \"PRECURSOR_CHARGE_KEY\": \"precursor_charge_onehot\",\n",
    "        \"FRAGMENTATION_TYPE_KEY\": \"method_nbr\",\n",
    "    }\n",
    "\n",
    "meta_data_keys=[\"collision_energy_aligned_normed\", \"precursor_charge_onehot\", \"method_nbr\"]\n",
    "\n",
    "model = PrositIntensityPredictor(\n",
    "    seq_length=config['dataset']['seq_length'],\n",
    "    alphabet=PTMS_ALPHABET,\n",
    "    use_prosit_ptm_features=False,\n",
    "    with_termini=False,\n",
    "    input_keys=input_mapping,\n",
    "    meta_data_keys=meta_data_keys\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=masked_spectral_distance,\n",
    "    metrics=[masked_pearson_correlation_distance]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dlomix.models.prosit.PrositIntensityPredictor at 0x7f36270e5f90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 07:00:03.007810: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 31457280 exceeds 10% of free system memory.\n",
      "2024-06-12 07:00:03.010455: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 31457280 exceeds 10% of free system memory.\n",
      "2024-06-12 07:00:03.014973: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 31457280 exceeds 10% of free system memory.\n",
      "2024-06-12 07:00:03.017199: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 31457280 exceeds 10% of free system memory.\n",
      "2024-06-12 07:00:03.019520: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 31457280 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 26s 2s/step - loss: 0.6998 - masked_pearson_correlation_distance: 0.6064 - val_loss: 0.6730 - val_masked_pearson_correlation_distance: 0.5657\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f362445dcf0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    dataset.tensor_train_data,\n",
    "    validation_data=dataset.tensor_val_data,\n",
    "    epochs=config['training']['num_epochs'],\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freezing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if weights are correctly assigned to trainable/non-trainable:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers with weigths: 21\n",
      "layers with trainable weigths: 21\n",
      "layers with non-trainable weigths: 0\n"
     ]
    }
   ],
   "source": [
    "print(f'layers with weigths: {len(model.weights)}')\n",
    "print(f'layers with trainable weigths: {len(model.trainable_weights)}')\n",
    "print(f'layers with non-trainable weigths: {len(model.non_trainable_weights)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freeze the whole model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers with weigths: 21\n",
      "layers with trainable weigths: 0\n",
      "layers with non-trainable weigths: 21\n"
     ]
    }
   ],
   "source": [
    "print(f'layers with weigths: {len(model.weights)}')\n",
    "print(f'layers with trainable weigths: {len(model.trainable_weights)}')\n",
    "print(f'layers with non-trainable weigths: {len(model.non_trainable_weights)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfreeze again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freeze individual layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to freeze certain layers (indicated by index)\n",
    "def freeze_layers(model:dlomix.models, layers:list[int]) -> None:\n",
    "    model.trainable = True\n",
    "    for l in layers:\n",
    "        model.layers[l].trainable = False\n",
    "    \n",
    "    # compile the model again to make changes take effect\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=masked_spectral_distance,\n",
    "        metrics=[masked_pearson_correlation_distance]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, False, False, True, True, True, True]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freeze_layers(model, [0,1,2])\n",
    "[model.layers[i].trainable for i in range(0, len(model.layers))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, False, False, True, True, True]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freeze_layers(model, [2,3])\n",
    "[model.layers[i].trainable for i in range(0, len(model.layers))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, False, False, False, False, False, False]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# freeze all layers except layer 1\n",
    "freeze_layers(model, range(1, len(model.layers)))\n",
    "[model.layers[i].trainable for i in range(0, len(model.layers))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, False, False, False, False, False, True]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# freeze all layers except last layer\n",
    "freeze_layers(model, range(0, len(model.layers)-1))\n",
    "[model.layers[i].trainable for i in range(0, len(model.layers))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, False, False, False, False, False, False]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# freeze all layers \n",
    "freeze_layers(model, range(0, len(model.layers)))\n",
    "[model.layers[i].trainable for i in range(0, len(model.layers))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, True, False, False, False, False, False]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# freeze all layers except the second layer \n",
    "layers_to_freeze = list(range(0, len(model.layers)))\n",
    "layers_to_freeze.pop(1)\n",
    "freeze_layers(model, layers_to_freeze)\n",
    "[model.layers[i].trainable for i in range(0, len(model.layers))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continue Training with frozen layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03843875, -0.04833046,  0.0237368 ,  0.0021462 ,  0.04882205,\n",
       "        0.00462924, -0.04129234, -0.04895075,  0.02260053,  0.02259899,\n",
       "       -0.00010501,  0.00306951, -0.04859496, -0.04148008,  0.00248486,\n",
       "       -0.03462191], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_weights = model.get_weights()\n",
    "original_weights[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_layers(model, [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 23s 2s/step - loss: 0.6710 - masked_pearson_correlation_distance: 0.5642 - val_loss: 0.6695 - val_masked_pearson_correlation_distance: 0.5604\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f35e03bd150>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train again while only first layer is trainable\n",
    "model.fit(\n",
    "    dataset.tensor_train_data,\n",
    "    validation_data=dataset.tensor_val_data,\n",
    "    epochs=1,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights in layer 0 stayed the same: True\n",
      "Weights in layer 1 stayed the same: False\n",
      "Weights in layer 2 stayed the same: False\n",
      "Weights in layer 3 stayed the same: False\n",
      "Weights in layer 4 stayed the same: False\n",
      "Weights in layer 5 stayed the same: False\n",
      "Weights in layer 6 stayed the same: False\n"
     ]
    }
   ],
   "source": [
    "# check which weights have changed\n",
    "# what tf happened to weights 18 - 21?\n",
    "retrained_weights = model.get_weights()\n",
    "print(f'Weights in layer 0 stayed the same: {(retrained_weights[0] == original_weights[0]).all()}')\n",
    "print(f'Weights in layer 1 stayed the same: {(retrained_weights[1] == original_weights[1]).all() & (retrained_weights[2] == original_weights[2]).all() & (retrained_weights[3] == original_weights[3]).all() & (retrained_weights[4] == original_weights[4]).all()}')\n",
    "print(f'Weights in layer 2 stayed the same: {(retrained_weights[5] == original_weights[5]).all() & (retrained_weights[6] == original_weights[6]).all() & (retrained_weights[7] == original_weights[7]).all()}')\n",
    "print(f'Weights in layer 3 stayed the same: {(retrained_weights[8] == original_weights[8]).all() & (retrained_weights[9] == original_weights[9]).all() & (retrained_weights[10] == original_weights[10]).all()}')\n",
    "print(f'Weights in layer 4 stayed the same: {(retrained_weights[11] == original_weights[11]).all()}')\n",
    "print(f'Weights in layer 5 stayed the same: {(retrained_weights[12] == original_weights[12]).all() & (retrained_weights[13] == original_weights[13]).all()}')\n",
    "print(f'Weights in layer 6 stayed the same: {(retrained_weights[14] == original_weights[14]).all() & (retrained_weights[15] == original_weights[15]).all() & (retrained_weights[16] == original_weights[16]).all() & (retrained_weights[17] == original_weights[17]).all()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freezing of individual sublayers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Function to see which layers and sublayers are trainable* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_trainability(model, sublayers = False):\n",
    "    for lay in model.layers:\n",
    "        if(sublayers):\n",
    "            print()\n",
    "        else:\n",
    "            print(f'{lay} trainable: {lay.trainable}')\n",
    "\n",
    "        if (sublayers):\n",
    "            try:\n",
    "                for lay2 in lay.layers:\n",
    "                    print(f'{lay2} trainable: {lay2.trainable}')\n",
    "            except(Exception):\n",
    "                print(f'{lay} trainable: {lay.trainable}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.src.layers.core.embedding.Embedding object at 0x7f36246d4610> trainable: False\n",
      "<keras.src.engine.sequential.Sequential object at 0x7f36246d7850> trainable: True\n",
      "<keras.src.engine.sequential.Sequential object at 0x7f36245cc6d0> trainable: True\n",
      "<keras.src.engine.sequential.Sequential object at 0x7f36245cd9f0> trainable: True\n",
      "<dlomix.layers.attention.AttentionLayer object at 0x7f36245cddb0> trainable: True\n",
      "<keras.src.engine.sequential.Sequential object at 0x7f36245ce710> trainable: True\n",
      "<keras.src.engine.sequential.Sequential object at 0x7f36245cf6a0> trainable: True\n"
     ]
    }
   ],
   "source": [
    "check_trainability(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<keras.src.layers.core.embedding.Embedding object at 0x7f36246d4610> trainable: False\n",
      "\n",
      "<keras.src.layers.rnn.bidirectional.Bidirectional object at 0x7f36246d5300> trainable: True\n",
      "<keras.src.layers.regularization.dropout.Dropout object at 0x7f36246d6980> trainable: True\n",
      "<keras.src.layers.rnn.gru.GRU object at 0x7f36246d6c50> trainable: True\n",
      "<keras.src.layers.regularization.dropout.Dropout object at 0x7f36246d7580> trainable: True\n",
      "\n",
      "<keras.src.layers.merging.concatenate.Concatenate object at 0x7f36246d7cd0> trainable: True\n",
      "<keras.src.layers.core.dense.Dense object at 0x7f36245cc070> trainable: True\n",
      "<keras.src.layers.regularization.dropout.Dropout object at 0x7f36245cc460> trainable: True\n",
      "\n",
      "<keras.src.layers.rnn.gru.GRU object at 0x7f36245cca60> trainable: True\n",
      "<keras.src.layers.regularization.dropout.Dropout object at 0x7f36245cd570> trainable: True\n",
      "<dlomix.layers.attention.DecoderAttentionLayer object at 0x7f36245cd840> trainable: True\n",
      "\n",
      "<dlomix.layers.attention.AttentionLayer object at 0x7f36245cddb0> trainable: True\n",
      "\n",
      "<keras.src.layers.merging.multiply.Multiply object at 0x7f36245ce320> trainable: True\n",
      "<keras.src.layers.reshaping.repeat_vector.RepeatVector object at 0x7f36245ce500> trainable: True\n",
      "\n",
      "<keras.src.layers.rnn.time_distributed.TimeDistributed object at 0x7f36245cf0a0> trainable: True\n",
      "<keras.src.layers.activation.leaky_relu.LeakyReLU object at 0x7f36245cf220> trainable: True\n",
      "<keras.src.layers.reshaping.flatten.Flatten object at 0x7f36245cf430> trainable: True\n"
     ]
    }
   ],
   "source": [
    "check_trainability(model, sublayers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.layers.core.embedding.Embedding at 0x7f7c801244f0>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.engine.sequential.Sequential at 0x7f7c80127730>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Does not work from this point on*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to recursively freeze layers \n",
    "def freeze_layers_rec(layer, layers_to_freeze) -> None:\n",
    "    # TODO: make function can go infinitely deep into the model layers to freeze only specific parts\n",
    "    if isinstance(layers_to_freeze, int):\n",
    "        print(layers_to_freeze)\n",
    "        print(layer)\n",
    "        layer.trainable = False\n",
    "    else:\n",
    "        for l in range(0, len(layers_to_freeze)):\n",
    "            print(layers_to_freeze[l])\n",
    "            freeze_layers_rec(layer.layers[layers_to_freeze[l][0]], l)\n",
    "\n",
    "\n",
    "# function to freeze certain layers of a model (indicated by index)\n",
    "def freeze_layers(model, layers_to_freeze) -> None:\n",
    "    # reset previous freezing configurations\n",
    "    model.trainable = True\n",
    "\n",
    "    # call the recursive function on the whole model\n",
    "    freeze_layers_rec(model, layers_to_freeze)\n",
    "\n",
    "    # compile the model again to make changes take effect\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=masked_spectral_distance,\n",
    "        metrics=[masked_pearson_correlation_distance]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<keras.src.layers.core.embedding.Embedding object at 0x7f7c801244f0> trainable: False\n",
      "\n",
      "<keras.src.layers.rnn.bidirectional.Bidirectional object at 0x7f7c801251e0> trainable: True\n",
      "<keras.src.layers.regularization.dropout.Dropout object at 0x7f7c80126860> trainable: True\n",
      "<keras.src.layers.rnn.gru.GRU object at 0x7f7c80126b30> trainable: True\n",
      "<keras.src.layers.regularization.dropout.Dropout object at 0x7f7c80127460> trainable: True\n",
      "\n",
      "<keras.src.layers.merging.concatenate.Concatenate object at 0x7f7c80127bb0> trainable: False\n",
      "<keras.src.layers.core.dense.Dense object at 0x7f7c80127f10> trainable: False\n",
      "<keras.src.layers.regularization.dropout.Dropout object at 0x7f7c80220340> trainable: False\n",
      "\n",
      "<keras.src.layers.rnn.gru.GRU object at 0x7f7c80220940> trainable: False\n",
      "<keras.src.layers.regularization.dropout.Dropout object at 0x7f7c80221450> trainable: False\n",
      "<dlomix.layers.attention.DecoderAttentionLayer object at 0x7f7c80221720> trainable: False\n",
      "\n",
      "<dlomix.layers.attention.AttentionLayer object at 0x7f7c80221c90> trainable: False\n",
      "\n",
      "<keras.src.layers.merging.multiply.Multiply object at 0x7f7c80222200> trainable: False\n",
      "<keras.src.layers.reshaping.repeat_vector.RepeatVector object at 0x7f7c802223e0> trainable: False\n",
      "\n",
      "<keras.src.layers.rnn.time_distributed.TimeDistributed object at 0x7f7c80222f80> trainable: False\n",
      "<keras.src.layers.activation.leaky_relu.LeakyReLU object at 0x7f7c80223100> trainable: False\n",
      "<keras.src.layers.reshaping.flatten.Flatten object at 0x7f7c80223310> trainable: False\n"
     ]
    }
   ],
   "source": [
    "for lay in model.layers:\n",
    "    print()\n",
    "    try:\n",
    "        for lay2 in lay.layers:\n",
    "            print(f'{lay2} trainable: {lay2.trainable}')\n",
    "    except(Exception):\n",
    "         print(f'{lay} trainable: {lay.trainable}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlomix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
