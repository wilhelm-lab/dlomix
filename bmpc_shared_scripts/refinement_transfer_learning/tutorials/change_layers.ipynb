{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to change the output or the input layer in a pre-trained PrositIntensityModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlomix\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the path to the pre-trained model file, this file needs the .keras suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_MODEL_DIR = '/cmnfs/proj/prosit_astral/bmpc_dlomix_group/models/baseline_models/noptm_baseline_full_bs1024/'\n",
    "MODEL_NAME = '85c6c918-4a2a-42e5-aab1-e666121c69a6.keras'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the model \\\n",
    "Normally it should work, if custom functions and classes are decorated with @keras.saving.register_keras_serializable() \\\n",
    "If not, Ssecify the custom objects of the model, here the masked spectral distance loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"prosit_intensity_predictor_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     multiple                  432       \n",
      "                                                                 \n",
      " sequential_5 (Sequential)   (None, 30, 512)           1996800   \n",
      "                                                                 \n",
      " sequential_6 (Sequential)   multiple                  4608      \n",
      "                                                                 \n",
      " sequential_7 (Sequential)   (None, 29, 512)           1576806   \n",
      "                                                                 \n",
      " encoder_att (AttentionLaye  multiple                  542       \n",
      " r)                                                              \n",
      "                                                                 \n",
      " sequential_8 (Sequential)   multiple                  0         \n",
      "                                                                 \n",
      " sequential_9 (Sequential)   (None, 174)               3078      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3582266 (13.67 MB)\n",
      "Trainable params: 3582266 (13.67 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from dlomix.losses import masked_spectral_distance\n",
    "model = keras.models.load_model(PATH_TO_MODEL_DIR + MODEL_NAME)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the output layer\n",
    "This corresponds to changing the regressor of the network \\\n",
    "You can either keep the dimensions and replace the trained weights with randomly initialized ones (default parameter) or \n",
    "change the output dimensions to fit a arbitrary number of ions (e.g. 1) for only b ions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlomix.models import PrositIntensityPredictor\n",
    "def change_output_layer(model: PrositIntensityPredictor, number_of_ions: int = 2):\n",
    "    model.len_fion = 3 * number_of_ions\n",
    "    model.regressor = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.TimeDistributed(\n",
    "            tf.keras.layers.Dense(model.len_fion), name=\"time_dense\"\n",
    "        ),\n",
    "        tf.keras.layers.LeakyReLU(name=\"activation\"),\n",
    "        tf.keras.layers.Flatten(name=\"out\"),\n",
    "    ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_output_layer(model, number_of_ions=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of the model can only be shown if called on a tensor the size of the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_dataset = dlomix.data.load_processed_dataset('/cmnfs/proj/prosit_astral/bmpc_dlomix_group/datasets/processed/transfer_learning_toy_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"prosit_intensity_predictor\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       multiple                  928       \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 30, 512)           1996800   \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   multiple                  4608      \n",
      "                                                                 \n",
      " sequential_2 (Sequential)   (None, 29, 512)           1576806   \n",
      "                                                                 \n",
      " encoder_att (AttentionLaye  multiple                  542       \n",
      " r)                                                              \n",
      "                                                                 \n",
      " sequential_3 (Sequential)   multiple                  0         \n",
      "                                                                 \n",
      " sequential_5 (Sequential)   (1024, 87)                1539      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3581223 (13.66 MB)\n",
      "Trainable params: 3581223 (13.66 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch, _ = next(iter(toy_dataset.tensor_train_data))\n",
    "model(batch)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the model has now the dimensions (batch_size, 87)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export XLA_FLAGS=--xla_gpu_cuda_data_dir=/usr/lib/cuda\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to recompile the model after changing the architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reinitialize the optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=dlomix.losses.masked_spectral_distance\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "8/8 [==============================] - 24s 2s/step - loss: 0.8992 - val_loss: 0.8338\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 16s 2s/step - loss: 0.8139 - val_loss: 0.7587\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f561b1a5810>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(toy_dataset.tensor_train_data, \n",
    "          validation_data=toy_dataset.tensor_val_data,\n",
    "          epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the input layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the input layer to accomodate a new modification means updating the alphabet of the model \\\n",
    "After that you can reinitialize the embedding layer with the ne alphabet size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the model can handle the new modification without the new embedding layer -> load model dataset with new modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"prosit_intensity_predictor_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     multiple                  928       \n",
      "                                                                 \n",
      " sequential_11 (Sequential)  (None, 30, 512)           1996800   \n",
      "                                                                 \n",
      " sequential_12 (Sequential)  multiple                  4608      \n",
      "                                                                 \n",
      " sequential_13 (Sequential)  (None, 29, 512)           1576806   \n",
      "                                                                 \n",
      " encoder_att (AttentionLaye  multiple                  542       \n",
      " r)                                                              \n",
      "                                                                 \n",
      " sequential_14 (Sequential)  multiple                  0         \n",
      "                                                                 \n",
      " sequential_15 (Sequential)  (None, 174)               3078      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3582762 (13.67 MB)\n",
      "Trainable params: 3582762 (13.67 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(PATH_TO_MODEL_DIR + MODEL_NAME)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_dataset_2 = dlomix.data.load_processed_dataset('/cmnfs/proj/prosit_astral/bmpc_dlomix_group/datasets/processed/new_modification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_input_layer(model: PrositIntensityPredictor, modifications: list = None):\n",
    "    # update the alphabet given the list of the new modifications, if there are any\n",
    "    if modifications:\n",
    "        for new_mod in modifications:\n",
    "            model.alphabet.update({new_mod: max(model.alphabet.values()) + 1})\n",
    "    # replace the embedding layer\n",
    "    model.embedding = tf.keras.layers.Embedding(\n",
    "        input_dim=len(model.alphabet) + 2,\n",
    "        output_dim=model.embedding_output_dim,\n",
    "        input_length=model.seq_length,\n",
    "        name='embedding'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_input_layer(model, ['M[UNIMOD:999]'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build model with a batch of the toy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"prosit_intensity_predictor_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_11 (Sequential)  (None, 30, 512)           1996800   \n",
      "                                                                 \n",
      " sequential_12 (Sequential)  multiple                  4608      \n",
      "                                                                 \n",
      " sequential_13 (Sequential)  (None, 29, 512)           1576806   \n",
      "                                                                 \n",
      " encoder_att (AttentionLaye  multiple                  542       \n",
      " r)                                                              \n",
      "                                                                 \n",
      " sequential_14 (Sequential)  multiple                  0         \n",
      "                                                                 \n",
      " sequential_15 (Sequential)  (None, 174)               3078      \n",
      "                                                                 \n",
      " embedding (Embedding)       multiple                  944       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3582778 (13.67 MB)\n",
      "Trainable params: 3582778 (13.67 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model(batch)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems with new modifications:\n",
    "* The new modification has to be processed correctly -> needs an entry in the alphabet used in the prepare_dataset.py file (maybe in a config specify the new modifications?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To efficiently apply transfer learning, you also need to freeze certain layers -> Lina\n",
    "Freezing the whole network except the regressor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlomix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
