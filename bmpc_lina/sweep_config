program: train.py
method: bayes
metric:
  name: val_loss
  goal: minimize
parameters:
  model:
    parameters:
      load_path:
        distribution: categorical
        values:
          - /cmnfs/proj/bmpc_dlomix/models/baseline_models/noptm_baseline_full_bs1024_naivemods/d961f940-d142-4102-9775-c1f8b4373c91.keras
  dataset:
    parameters:
      name:
        distribution: categorical
        values:
          - noptm_baseline_small_swapped_ions
      hf_home:
        distribution: categorical
        values:
          - /cmnfs/proj/bmpc_dlomix/datasets
      hf_cache:
        distribution: categorical
        values:
          - /cmnfs/proj/bmpc_dlomix/datasets/hf_cache
      batch_size:
        distribution: int_uniform
        min: 512
        max: 2048
      seq_length:
        distribution: int_uniform
        min: 15
        max: 60
      parquet_path:
        distribution: categorical
        values:
          - /cmnfs/proj/bmpc_dlomix/datasets/parquet/noptm_baseline_small_swapped_ions
      processed_path:
        distribution: categorical
        values:
          - /cmnfs/proj/bmpc_dlomix/datasets/processed/noptm_baseline_small_swapped_ions
  project:
    distribution: categorical
    values:
      - swapped ions rl
  training:
    parameters:
      num_epochs:
        distribution: int_uniform
        min: 50
        max: 200
      learning_rate:
        distribution: uniform
        min: 0.00005
        max: 0.0002
      early_stopping:
        parameters:
          patience:
            distribution: int_uniform
            min: 5
            max: 20
          min_delta:
            distribution: uniform
            min: 0.000005
            max: 0.00002
      lr_warmup_linear:
        parameters:
          end_lr:
            distribution: uniform
            min: 0.00005
            max: 0.0002
          start_lr:
            distribution: uniform
            min: 5e-7
            max: 0.000002
          num_epochs:
            distribution: int_uniform
            min: 0
            max: 158
      lr_scheduler_plateau:
        parameters:
          factor:
            distribution: uniform
            min: 0.25
            max: 1
          cooldown:
            distribution: int_uniform
            min: 1
            max: 2
          patience:
            distribution: int_uniform
            min: 2
            max: 8
          min_delta:
            distribution: uniform
            min: 0.00005
            max: 0.0002
  processing:
    parameters:
      cuda_device_nr:
        distribution: categorical
        values:
          - "1"
  refinement_transfer_learning:
    parameters:
      freeze_layers:
        parameters:
          release_after_epochs:
            distribution: int_uniform
            min: 0
            max: 156
          is_last_layer_trainable:
            distribution: categorical
            values:
              - "true"
              - "false"
          is_first_layer_trainable:
            distribution: categorical
            values:
              - "true"
              - "false"



python rl_tl_training_agent.py --config config_files/noptm_baseline_small_duplicated_ions.yaml --sweep-id "mapra_dlomix/duplicated ions tl/pnv0gx3f" --sweep-count 20 --cuda-device-nr 1