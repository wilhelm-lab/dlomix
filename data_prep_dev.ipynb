{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import re \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_files_into_df(directory_path=\"../data/\", file_types=['.parquet', '.tsv', '.csv']):\n",
    "    \"\"\"\n",
    "    Combines all files in a directory into one DataFrame.\n",
    "    @param directory_path: str, path to the directory containing the files\n",
    "    @param file_types: list, list of file types to be imported\n",
    "    @return: df: DataFrame\n",
    "    \"\"\"\n",
    "    # Map file extensions to their respective pandas read functions and parameters\n",
    "    read_funcs = {\n",
    "        '.parquet': (pd.read_parquet, {'engine': 'fastparquet'}),\n",
    "        '.tsv': (pd.read_csv, {'sep': '\\t'}),\n",
    "        '.csv': (pd.read_csv, {})\n",
    "    }\n",
    "    \n",
    "    message_prefix = \"Step 1/? complete.\"\n",
    "\n",
    "    dfs = []\n",
    "    # Iterate through all files in the specified directory\n",
    "    for file in os.listdir(directory_path):\n",
    "        file_path = os.path.join(directory_path, file)\n",
    "        file_extension = os.path.splitext(file)[1]\n",
    "        \n",
    "        # Check if the file extension is in the list of types to read\n",
    "        if file_extension in file_types:\n",
    "            read_func, params = read_funcs.get(file_extension, (None, None))\n",
    "            if read_func:\n",
    "                df = read_func(file_path, **params)\n",
    "                dfs.append(df)\n",
    "            else:\n",
    "                print(f\"Skipping unsupported file type: {file_extension}\")\n",
    "\n",
    "    # Combine all DataFrames in the list into a single DataFrame\n",
    "    if dfs:\n",
    "        df = pd.concat(dfs, ignore_index=True)\n",
    "        print(f\"{message_prefix} Combined {len(dfs)} files into one DataFrame.\")\n",
    "    else:\n",
    "        df = pd.DataFrame()\n",
    "        print(\"No files combined.\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dataframe_columns(df, columns_to_keep=['modified_sequence', 'precursor_charge', 'precursor_intensity']):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to keep only the specified columns.\n",
    "    @param df: DataFrame, the DataFrame to filter\n",
    "    @param columns_to_keep: list, the names of the columns to keep\n",
    "    @return: df_filtered: DataFrame\n",
    "    \"\"\"\n",
    "    df_filtered = df[columns_to_keep].copy() if all(col in df for col in columns_to_keep) else df\n",
    "    print(f\"Step 2/? complete. Removed {len(df.columns) - len(df_filtered.columns)} columns from the DataFrame.\")\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_na(df, column=\"precursor_intensity\"):\n",
    "    \"\"\"\n",
    "    Drop all rows with NaN values in a specific column\n",
    "    Default: drop na from precursor_intensity column\n",
    "    @param df: DataFrame\n",
    "    @param column: column to drop NaN values from\n",
    "    @return: df: DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    df = df[df[column].notna()]\n",
    "    print(f\"Step 3/? complete. Dropped rows with NaN for intensities.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_desired_charges(df, charge_list=[1, 2, 3, 4, 5, 6], min_count=None):\n",
    "    \"\"\"\n",
    "    Keep only desired charge states and filter out charges with counts less than min_count.\n",
    "    Default: keep charge states 1-6 with no minimum count filtering.\n",
    "\n",
    "    @param df: DataFrame\n",
    "    @param charge_list: list of charge states to be kept\n",
    "    @param min_count: minimum count of charge states to be retained\n",
    "    \"\"\"\n",
    "    message_prefix = \"Step 4/? complete.\"\n",
    "    summary_message = \"\" \n",
    "\n",
    "    if min_count is not None:\n",
    "        charge_counts = df[\"precursor_charge\"].value_counts()\n",
    "        filtered_charges = [\n",
    "            charge for charge in charge_list if charge_counts.get(charge, 0) >= min_count\n",
    "        ]\n",
    "        \n",
    "        removed_charges = set(charge_list) - set(filtered_charges)\n",
    "        if removed_charges:\n",
    "            summary_message += f\"Removed charge states with less than {min_count} occurrences in the dataset. \"\n",
    "            summary_message += f\"Charges removed: {sorted(removed_charges)}. \"\n",
    "        charge_list = filtered_charges\n",
    "    else:\n",
    "        summary_message += f\"Focused on keeping charge states within {charge_list}. \"\n",
    "\n",
    "    # Apply filtering based on the updated charge_list\n",
    "    df_filtered = df[df[\"precursor_charge\"].isin(charge_list)]\n",
    "\n",
    "    final_message = f\"{message_prefix} {summary_message}Resulting in {len(df_filtered)} entries.\"\n",
    "    print(final_message)\n",
    "\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_unique_sequences(df):\n",
    "    \"\"\"\n",
    "    Aggregates all sequences to unique sequences\n",
    "    @param df: DataFrame\n",
    "    @return: df: DataFrame\n",
    "    \"\"\"\n",
    "    df = (\n",
    "        df.groupby(\"modified_sequence\", as_index=False)[[\"precursor_charge\", \"precursor_intensity\"]]\n",
    "        .agg(list)\n",
    "    )\n",
    "    print(f\"Step 5/? complete. Aggregated all sequences to unique sequences.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_rare_sequence_lengths(df, representation_threshold=100):\n",
    "    \"\"\"\n",
    "    Remove sequences of specific length represented less than a certain number of times.\n",
    "    \n",
    "    @param df: DataFrame containing a \"modified_sequence\" column\n",
    "    @param representation_threshold: int, threshold for the number of times a sequence length must be represented\n",
    "    @return: tuple of (DataFrame, int), where DataFrame contains only sequence lengths represented more than\n",
    "             representation_threshold times, and int is the length of the longest sequence\n",
    "    \"\"\"\n",
    "    before_len = len(df)\n",
    "    # Calculate sequence lengths directly within the groupby and count operation\n",
    "    sequence_lengths = df[\"modified_sequence\"].str.len()\n",
    "    # Identify sequence lengths that meet the representation threshold\n",
    "    valid_lengths = sequence_lengths.value_counts()[lambda x: x >= representation_threshold].index\n",
    "    # Filter the DataFrame based on valid sequence lengths\n",
    "    df_filtered = df[sequence_lengths.isin(valid_lengths)].copy()\n",
    "    padding_length = sequence_lengths.max()\n",
    "    after_len = len(df_filtered)\n",
    "    \n",
    "    print(\n",
    "        f\"Step 6/? complete. Removed {before_len - after_len} of {before_len} sequences because their sequence length \"\n",
    "        f\"is represented less than {representation_threshold} times.\"\n",
    "    )\n",
    "    return df_filtered, padding_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_vocabulary(df):\n",
    "    \"\"\"\n",
    "    Find all UNIMOD annotations and add them to the vocabulary\n",
    "    (The length of the vocabulary +1 is used later for the embedding layer)\n",
    "    @param df: DataFrame\n",
    "    @return: vocabulary: list, list of all amino acids and modifications\n",
    "    @return: vocab_len: int, length of the vocabulary\n",
    "    \"\"\"\n",
    "    vocabulary = []\n",
    "    vocabulary += list(\"XACDEFGHIKLMNPQRSTVWY\")\n",
    "    annotations = re.findall(r\"(\\w\\[UNIMOD:\\d+])\", \" \".join(df[\"modified_sequence\"]))\n",
    "    for item in annotations:\n",
    "        if item not in vocabulary:\n",
    "            vocabulary.append(item)\n",
    "    vocab_len = len(vocabulary)\n",
    "    \n",
    "    print(f\"Step 7/? complete. Completed vocabulary with {vocab_len} entries.\")\n",
    "    return vocabulary, vocab_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO obsolete as it is now handeled by add_labels\n",
    "def encode_charge_states(df, charge_states=None):\n",
    "    \"\"\"\n",
    "    Encode all occuring charge states per unique sequence in a binary vector\n",
    "\n",
    "    input: df containing \"precursor_charge\" column output: df containing an additional \"charge_state_vector\"\n",
    "    column encoding all occuring charge states per unique sequence in a binary vector\n",
    "    @param df: DataFrame\n",
    "    @return: df: DataFrame\n",
    "    \"\"\"\n",
    "    df[\"charge_state_vector\"] = df[\"precursor_charge\"].apply(\n",
    "        lambda x: [\n",
    "            1 if i in x else 0 for i in range(charge_states[0], charge_states[-1] + 1)\n",
    "        ]\n",
    "    )\n",
    "    print(\n",
    "        f\"Step ?/? complete. Encoded all occuring charge states per unique sequence in a binary vector.\"\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select most abundand charge states for TASK 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By count // OBSOLETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_most_abundant_by_count(df, charge_list=None):\n",
    "    \"\"\"\n",
    "    Selects the most abundant charge state by count.\n",
    "    \n",
    "    @param df: DataFrame with a 'precursor_charge' column containing a list of charge states.\n",
    "    @return: DataFrame with an added 'most_abundant_by_count' and 'most_abundant_charge_vector' column.\n",
    "    \"\"\"\n",
    "    # Define a function to find the most common element in a list\n",
    "    def most_common(lst):\n",
    "        return Counter(lst).most_common(1)[0][0]\n",
    "\n",
    "    # Apply the function to each row in the 'precursor_charge' column and assign to a new column\n",
    "    df['most_abundant_charge_by_count'] = df['precursor_charge'].apply(most_common)\n",
    "\n",
    "    if charge_list is None:\n",
    "        charge_list = [1, 2, 3, 4, 5, 6]\n",
    "    df[\"most_abundant_charge_by_count_vector\"] = df[\"most_abundant_charge_by_count\"].apply(\n",
    "        lambda x: [1 if x == i else 0 for i in charge_list]\n",
    "    )\n",
    "    print(\n",
    "        f\"Step ?/? complete. Selected most abundant charge state by count and generated one-hot encoding\"\n",
    "    )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topK_charge_states_by_count(df, k=2):\n",
    "    \"\"\"\n",
    "    Get top-k charge states for each sequence according to the count in precursor_charge.\n",
    "    Default: k=2\n",
    "    @param df: DataFrame with a 'precursor_charge' column containing a list of charge states.\n",
    "    @param k: int, number of top charge states to be selected\n",
    "    @return: DataFrame with an added column for top-k charge states.\n",
    "    \"\"\"\n",
    "\n",
    "    def get_topK_charge_counts(charge_list):\n",
    "        # Count the occurrences of each charge state and get the top-k\n",
    "        count = Counter(charge_list)\n",
    "        top_k = [charge for charge, _ in count.most_common(k)]\n",
    "        return top_k\n",
    "\n",
    "    # Apply the function to each row in the 'precursor_charge' column and assign to a new column\n",
    "    df[f\"top_{k}_charge_states_by_count\"] = df['precursor_charge'].apply(get_topK_charge_counts)\n",
    "\n",
    "    print(f\"Step ?/? complete. Selected top {k} charge states per sequence based on count.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "def select_most_abundant_charge_by_intensity(df, aggregation='max'):\n",
    "    charge_col = f'charge_by_{aggregation}_intensity'\n",
    "    intensity_col = f'{aggregation}_intensity'\n",
    "    df[charge_col] = None\n",
    "    df[intensity_col] = None\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        charges = row['precursor_charge']\n",
    "        intensities = row['precursor_intensity']\n",
    "\n",
    "        # Aggregate intensities for each unique charge\n",
    "        charge_intensity_dict = {}\n",
    "        for charge, intensity in zip(charges, intensities):\n",
    "            if charge in charge_intensity_dict:\n",
    "                charge_intensity_dict[charge].append(intensity)\n",
    "            else:\n",
    "                charge_intensity_dict[charge] = [intensity]\n",
    "\n",
    "        # Calculate the average or maximum intensity for each charge\n",
    "        if aggregation == 'avg':\n",
    "            avg_intensity = {charge: sum(charge_intensity_dict[charge]) / len(charge_intensity_dict[charge]) for charge in charge_intensity_dict}\n",
    "            most_abundant_charge = max(avg_intensity, key=avg_intensity.get)\n",
    "            selected_intensity = avg_intensity[most_abundant_charge]\n",
    "        elif aggregation == 'max':\n",
    "            max_intensity = {charge: max(charge_intensity_dict[charge]) for charge in charge_intensity_dict}\n",
    "            most_abundant_charge = max(max_intensity, key=max_intensity.get)\n",
    "            selected_intensity = max_intensity[most_abundant_charge]\n",
    "\n",
    "        df.at[index, charge_col] = most_abundant_charge\n",
    "        df.at[index, intensity_col] = selected_intensity\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_abundant_charges_by_intensity(df, k=1, aggregation='max'):\n",
    "    # Define new columns for the top-k most abundant charges and their intensities\n",
    "    charge_col = f'top_{k}_abundant_charges_by_{aggregation}'\n",
    "    intensity_col = f'top_{k}_{aggregation}_intensities'\n",
    "    \n",
    "    # Initialize new columns\n",
    "    df[charge_col] = None\n",
    "    df[intensity_col] = None\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        charges = row['precursor_charge']\n",
    "        intensities = row['precursor_intensity']\n",
    "\n",
    "        # Aggregate intensities for each unique charge\n",
    "        charge_intensity_dict = {}\n",
    "        for charge, intensity in zip(charges, intensities):\n",
    "            charge_intensity_dict.setdefault(charge, []).append(intensity)\n",
    "\n",
    "        # Calculate the average or maximum intensity for each charge\n",
    "        if aggregation == 'avg':\n",
    "            charge_intensity_aggregated = {charge: sum(intensities) / len(intensities) for charge, intensities in charge_intensity_dict.items()}\n",
    "        elif aggregation == 'max':\n",
    "            charge_intensity_aggregated = {charge: max(intensities) for charge, intensities in charge_intensity_dict.items()}\n",
    "\n",
    "        # Sort the charges by their aggregated intensity and select the top-k\n",
    "        sorted_charges = sorted(charge_intensity_aggregated.items(), key=lambda item: item[1], reverse=True)[:k]\n",
    "        top_k_charges, top_k_intensities = zip(*sorted_charges) if sorted_charges else ([], [])\n",
    "\n",
    "        # Assign the top-k charges and their intensities to the dataframe\n",
    "        df.at[index, charge_col] = list(top_k_charges)\n",
    "        df.at[index, intensity_col] = list(top_k_intensities)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_labels(df, aggregation='max'):\n",
    "    df['most_abundant_one_hot'] = None # TASK 1\n",
    "    df['charge_state_vector'] = None # TASK 2 / 3\n",
    "    df['normalized_intensity_distribution'] = None # TASK 3\n",
    "      \n",
    "    # Determine the maximum charge state across all sequences\n",
    "    max_charge_state = max(max(charges) for charges in df['precursor_charge'])\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        charges = row['precursor_charge']\n",
    "        intensities = row['precursor_intensity']\n",
    "\n",
    "        # Create the charge_state_vector\n",
    "        charge_state_vector = [1 if i in charges else 0 for i in range(1, max_charge_state + 1)]\n",
    "        \n",
    "        # Map intensities to their respective charge states\n",
    "        charge_intensity_dict = {charge: [] for charge in charges}\n",
    "        for charge, intensity in zip(charges, intensities):\n",
    "            charge_intensity_dict[charge].append(intensity)\n",
    "\n",
    "        # Determine the most abundant charge based on the specified aggregation\n",
    "        if aggregation == 'avg':\n",
    "            aggregated_intensity = {charge: sum(intensities) / len(intensities) for charge, intensities in charge_intensity_dict.items()}\n",
    "        else:  # 'max'\n",
    "            aggregated_intensity = {charge: max(intensities) for charge, intensities in charge_intensity_dict.items()}\n",
    "        \n",
    "        most_abundant_charge = max(aggregated_intensity, key=aggregated_intensity.get)\n",
    "\n",
    "        # Calculate the normalized intensity distribution\n",
    "        total_intensity = sum(sum(intensities) for intensities in charge_intensity_dict.values())\n",
    "        normalized_distribution = [sum(charge_intensity_dict.get(i, [])) / total_intensity for i in range(1, max_charge_state + 1)]\n",
    "\n",
    "        # One-hot encode the most abundant charge\n",
    "        one_hot_most_abundant_charge = [1 if i == most_abundant_charge else 0 for i in range(1, max_charge_state + 1)]\n",
    "        \n",
    "        df.at[index,'most_abundant_one_hot'] = one_hot_most_abundant_charge\n",
    "        df.at[index, 'charge_state_vector'] = charge_state_vector\n",
    "        df.at[index, 'normalized_intensity_distribution'] = normalized_distribution\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_charge_state_encodings(df, aggregation='max'):\n",
    "    '''\n",
    "    Calculate the most abundant charge state for each sequence based on the precursor intensity\n",
    "    and generate the charge state vector and one-hot encoded vector for the most abundant charge.\n",
    "    '''\n",
    "    df['one_hot_most_abundant_charge'] = None\n",
    "    df['charge_state_vector'] = None\n",
    "\n",
    "    # Determine the maximum charge state across all sequences to define the vector lengths\n",
    "    max_charge_state = max(max(charges) for charges in df['precursor_charge'])\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        charges = row['precursor_charge']\n",
    "        intensities = row['precursor_intensity']\n",
    "\n",
    "        # Map intensities to their respective charge states\n",
    "        charge_intensity_dict = {charge: [] for charge in charges}\n",
    "        for charge, intensity in zip(charges, intensities):\n",
    "            charge_intensity_dict[charge].append(intensity)\n",
    "\n",
    "        # Aggregate intensities for determining the most abundant charge\n",
    "        if aggregation == 'avg':\n",
    "            aggregated_intensity = {charge: sum(intensities) / len(intensities) for charge, intensities in charge_intensity_dict.items()}\n",
    "        else:  # max\n",
    "            aggregated_intensity = {charge: max(intensities) for charge, intensities in charge_intensity_dict.items()}\n",
    "        \n",
    "        most_abundant_charge = max(aggregated_intensity, key=aggregated_intensity.get)\n",
    "\n",
    "        # Generate the one-hot encoded vector for the most abundant charge\n",
    "        one_hot_vector = [1 if charge == most_abundant_charge else 0 for charge in range(1, max_charge_state + 1)]\n",
    "        \n",
    "        # Generate the charge state vector for all charges\n",
    "        charge_state_vector = [1 if charge in charges else 0 for charge in range(1, max_charge_state + 1)]\n",
    "\n",
    "        df.at[index, 'one_hot_most_abundant_charge'] = one_hot_vector\n",
    "        df.at[index, 'charge_state_vector'] = charge_state_vector\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_most_abundant_charge(df, aggregation='max'):\n",
    "    '''\n",
    "    TASK 1: Calculate the most abundant charge state for each sequence based on the precursor intensity.\n",
    "    '''\n",
    "    most_abundant_charge = []\n",
    "    for charges, intensities in zip(df['precursor_charge'], df['precursor_intensity']):\n",
    "        charge_intensity_dict = {charge: [] for charge in charges}\n",
    "        for charge, intensity in zip(charges, intensities):\n",
    "            charge_intensity_dict[charge].append(intensity)\n",
    "        \n",
    "        if aggregation == 'avg':\n",
    "            aggregated_intensity = {charge: sum(intensities) / len(intensities) for charge, intensities in charge_intensity_dict.items()}\n",
    "        else:  # max\n",
    "            aggregated_intensity = {charge: max(intensities) for charge, intensities in charge_intensity_dict.items()}\n",
    "        \n",
    "        most_abundant_charge.append(max(aggregated_intensity, key=aggregated_intensity.get))\n",
    "    \n",
    "    df['most_abundant_charge_by_intensity'] = most_abundant_charge\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_charge_state_vector(df):\n",
    "    '''\n",
    "    TASK 2: Generate a binary vector for each sequence indicating the presence of each charge state.\n",
    "    '''\n",
    "    max_charge_state = max(max(charges) for charges in df['precursor_charge'])\n",
    "    charge_state_vector = [[1 if i in charges else 0 for i in range(1, max_charge_state + 1)] for charges in df['precursor_charge']]\n",
    "    \n",
    "    df['charge_state_vector'] = charge_state_vector\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_normalized_intensity_distribution(df):\n",
    "    '''\n",
    "    TASK 3: Compute the normalized intensity distribution for each sequence.\n",
    "    '''\n",
    "    normalized_intensity_distribution = []\n",
    "    for charges, intensities in zip(df['precursor_charge'], df['precursor_intensity']):\n",
    "        total_intensity = sum(intensities)\n",
    "        charge_intensity_dict = {charge: 0 for charge in charges}\n",
    "        for charge, intensity in zip(charges, intensities):\n",
    "            charge_intensity_dict[charge] += intensity\n",
    "        max_charge_state = max(charges)\n",
    "        distribution = [charge_intensity_dict.get(i, 0) / total_intensity for i in range(1, max_charge_state + 1)]\n",
    "        normalized_intensity_distribution.append(distribution)\n",
    "    \n",
    "    df['normalized_intensity_distribution'] = normalized_intensity_distribution\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO obsolete as it is now handeled by add_labels\n",
    "def one_hot_encode_charge(df, charge_list=None):\n",
    "    \"\"\"\n",
    "    One-hot encodes the most abundant charge state\n",
    "    @param df: DataFrame\n",
    "    @param charge_list: list, list of charge states\n",
    "    @return: df: DataFrame\n",
    "    \"\"\"\n",
    "    if charge_list is None:\n",
    "        charge_list = [1, 2, 3, 4, 5, 6]\n",
    "    df[\"most_abundant_charge_vector\"] = df[\"most_abundant_charge\"].apply(\n",
    "        lambda x: [1 if x == i else 0 for i in charge_list]\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prep process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = combine_files_into_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = filter_dataframe_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = drop_na(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = keep_desired_charges(df, charge_list=[1,2,3,4,5,6,7], min_count=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_df = aggregate_unique_sequences(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, max_seq_len = remove_rare_sequence_lengths(aggregated_df, representation_threshold=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_vocabulary, vocab_len = complete_vocabulary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = select_most_abundant_charge_by_intensity(df, aggregation='max')\n",
    "df = select_most_abundant_charge_by_intensity(df, aggregation='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_labels(df, aggregation='max')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST CASES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = {\n",
    "    \"modified_sequence\": [\"A\"]*6 + [\"B\"]*5 + [\"C\"]*4 + [\"D\"]*3 + [\"E\"]*2 + [\"F\"]*3 + [\"G\"]*4 + [\"H\"]*3 + [\"I\"]*5 + [\"J\"] + [\"X\"]*6,\n",
    "    \"precursor_charge\": [2, 2, 2, 1, 3, 2, 2, 2, 1, 1, 3, 1, 1, 2, 2, 3, 3, 2, 1, 1, 2, 2, 2, 1, 1, 2, 3, 3, 3, 2, 4, 4, 4, 4, 5, 2, 1, 1, 1, 1, 2, 2],\n",
    "    \"precursor_intensity\": [10, 20, 30, 40, 15, 25, 50, 60, 70, 80, 90, 100, 200, 150, 50, 300, 500, 400, 10, 20, 30, 40, 50, 60, 70, 65, 60, 100, 200, 300, 400, 500, 600, 700, 800, 900, 550, 560, 570, 550, 200, 900]\n",
    "}\n",
    "test_data = pd.DataFrame(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5/? complete. Aggregated all sequences to unique sequences.\n"
     ]
    }
   ],
   "source": [
    "aggregated_test_data = aggregate_unique_sequences(test_data)\n",
    "aggregated_test_data = select_most_abundant_charge_by_intensity(aggregated_test_data, aggregation='max')\n",
    "aggregated_test_data = generate_charge_state_encodings(aggregated_test_data)\n",
    "aggregated_test_data = compute_normalized_intensity_distribution(aggregated_test_data)\n",
    "aggregated_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pcp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
