{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7YWkUVjVr7qJ"
   },
   "source": [
    "# Peptide Detectability (Training and fine tuning) \n",
    "\n",
    "This notebook is prepared to be run in Google [Colaboratory](https://colab.research.google.com/). In order to train the model faster, please change the runtime of Colab to use Hardware Accelerator, either GPU or TPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S3DlTOq3r7qM"
   },
   "source": [
    "This notebook provides a concise walkthrough of the process for reading a dataset, training, and fine-tuning a model for peptide detectability prediction. \n",
    "\n",
    "The dataset used in this example is derived from:\n",
    "\n",
    "- **ProteomTools Dataset**: Includes data from the PRIDE repository with the following identifiers: `PXD004732`, `PXD010595`, and `PXD021013`.\n",
    "- **MAssIVE Dataset**: Deposited in the ProteomeXchange Consortium via the MAssIVE partner repository with the identifier `PXD024364`.\n",
    "\n",
    "The framework being used is a custom wrapper on top of Keras/TensorFlow. The working name of the package is for now DLOmix -  `dlomix`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installing the DLOmix Package\n",
    "\n",
    "If you haven't installed the DLOmix package yet, you need to do so before running the code. \n",
    "\n",
    "You can install the DLOmix package using pip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aO-69zbKsGey",
    "outputId": "c2064411-9f80-47e6-ca5b-312d547e0f6a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # install the DLOmix package in the current environment using pip\n",
    "\n",
    "# !python -m pip install -q git+https://github.com/wilhelm-lab/dlomix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mo7H9qzWr7qN"
   },
   "source": [
    "#### Importing Required Libraries\n",
    "\n",
    "Before running the code, ensure you import all the necessary libraries. These imports are essential for accessing the functionalities needed for data processing, model training, and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('C:/Users/JZ05DL/OneDrive - Aalborg Universitet/Documents/GitHub/dlomix/src')\n",
    "sys.path.append('C:/Users/JZ05DL/OneDrive - Aalborg Universitet/Documents/GitHub/dlomix/src/dlomix/data')\n",
    "sys.path.append('C:/Users/JZ05DL/OneDrive - Aalborg Universitet/Documents/GitHub/dlomix/src/dlomix/models')\n",
    "sys.path.append('C:/Users/JZ05DL/OneDrive - Aalborg Universitet/Documents/GitHub/dlomix/src/dlomix/reports')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l0CS0tFur7qN",
    "outputId": "664e0978-980a-4254-90d1-61e9f1603234"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['META_DATA', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import dlomix\n",
    "\n",
    "import os\n",
    "print([x for x in dir(dlomix)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JsgPZb_Mr7qP"
   },
   "source": [
    "- `constants`: constants to be used in the framework (e.g. Aminoacid alphabet mapping)\n",
    "- `data`:  classes for representing dataset, wrappers around TensorFlow Dataset\n",
    "- `eval`: custom evaluation metrics implemented in Keras/TF to work as `metrics` for model training\n",
    "- `layers`: custom layer implementation required for the different models\n",
    "- `models`: different model implementations (e.g. Detectability Prediction)\n",
    "- `pipelines`: complete pipelines to run a task (e.g. Retention Time prediction)\n",
    "- `utils`: helper modules\n",
    "\n",
    "**Note**: reports and pipelines are work-in-progress, some funtionalities are not complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "41qXroyKr7qP"
   },
   "source": [
    "## 1. Load Data for Training\n",
    "\n",
    "You can import the `detectability_dataset` class and create an instance to manage data for training, validation, and testing. This instance handles TensorFlow dataset objects and allows for easy control of dataset splits.\n",
    "\n",
    "#### Parameters\n",
    "\n",
    "- **data_source** (`str`, `tuple of two numpy.ndarray`, `numpy.ndarray`): Specifies the data source. This can be a tuple of two arrays (sequences and classes), a single array (sequences), which is useful for test data, or a file path to a CSV file. Defaults to `None`.\n",
    "\n",
    "- **protein_data** (`str`, `numpy.ndarray`): Specifies the protein data. This can be a single array with protein names or IDs, or the name of the column with protein information in the CSV file if a file path is provided. Defaults to `'proteins'`.\n",
    "\n",
    "- **sep** (`str`): Separator used in the CSV file if the data source is a CSV file. Defaults to `\",\"`.\n",
    "\n",
    "- **sequence_col** (`str`): Name of the column containing sequences in the CSV file. Defaults to `\"sequences\"`.\n",
    "\n",
    "- **classes_col** (`str`): Name of the column containing classes in the CSV file. Defaults to `\"classes\"`.\n",
    "\n",
    "- **split_on_protein** (`bool`): Determines if the dataset should be split based on proteins, ensuring that all peptides from a specific protein are kept together. Requires `protein_data` to be provided. Defaults to `False`.\n",
    "\n",
    "- **seq_length** (`int`): Maximum sequence length. Sequences longer than this length will be removed, and shorter sequences will be padded. Defaults to `40`.\n",
    "\n",
    "- **batch_size** (`int`): Batch size for training. Defaults to `32`.\n",
    "\n",
    "- **val_ratio** (`float`): Fraction of the dataset to be used for validation. Defaults to `0.1` (10%).\n",
    "\n",
    "- **test_ratio** (`float`): Fraction of the dataset to be used for testing. Defaults to `0.2` (20%).\n",
    "\n",
    "- **seed** (`int`): Seed for reproducible data splitting. Defaults to `21`.\n",
    "\n",
    "- **test** (`bool`): Indicates if the dataset is used solely for testing. Defaults to `False`.\n",
    "\n",
    "- **sample_run** (`bool`): Limits the number of examples for testing and debugging purposes. Defaults to `False`.\n",
    "\n",
    "\n",
    "**Note**: If class labels are provided, the following encoding scheme should be used:\n",
    "- **Non-Flyer**: 0\n",
    "- **Weak Flyer**: 1\n",
    "- **Intermediate Flyer**: 2\n",
    "- **Strong Flyer**: 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "RiXz_epEr7qQ"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdlomix\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdetectability_dataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m detectability_dataset\n",
      "File \u001b[1;32mC:\\Users/JZ05DL/OneDrive - Aalborg Universitet/Documents/GitHub/dlomix/src\\dlomix\\data\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcharge_state\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChargeStateDataset\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PeptideDataset, load_processed_dataset\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfragment_ion_intensity\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FragmentIonIntensityDataset\n",
      "File \u001b[1;32mC:\\Users/JZ05DL/OneDrive - Aalborg Universitet/Documents/GitHub/dlomix/src\\dlomix\\data\\charge_state.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Callable, Dict, List, Optional, Union\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ALPHABET_UNMOD\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PeptideDataset\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EncodingScheme\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mChargeStateDataset\u001b[39;00m(PeptideDataset):\n",
      "File \u001b[1;32mC:\\Users/JZ05DL/OneDrive - Aalborg Universitet/Documents/GitHub/dlomix/src\\dlomix\\data\\dataset.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Callable, Dict, List, Optional, Union\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, DatasetDict, Sequence, Value, load_dataset, load_from_disk\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ALPHABET_UNMOD\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DatasetConfig\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "from dlomix.data.detectability_dataset import detectability_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATAPATH = './example_dataset/detectability_data.csv'\n",
    "\n",
    "max_pep_length = 40\n",
    "BATCH_SIZE = 128\n",
    "            \n",
    "detectability_data = detectability_dataset(data_source = TRAIN_DATAPATH, \n",
    "                                           #protein_data = np.array([x.upper() for x in protein_data]),\n",
    "                                           seq_length = max_pep_length,\n",
    "                                           split_on_protein = False, \n",
    "                                           batch_size = BATCH_SIZE, \n",
    "                                           val_ratio = 0.1, \n",
    "                                           test_ratio = 0.2, \n",
    "                                           test = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_UUzvcHGr7qR"
   },
   "source": [
    "The `detectability_dataset` class can be directly integrated with both standard and custom `Keras` models. This dataset wrapper provides predefined splits for training, validation, and testing. These subsets can be accessed via the attributes `.train_data`, `.val_data`, and `.test_data`. Each subset's length is represented in batches, where the total number of examples is calculated as `total examples = batch_size x len(subset)`.\n",
    "\n",
    "If the parameter `test=True` is set, only the test dataset is generated, skipping the training and validation splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y1l6YedCr7qS",
    "outputId": "72576b1a-698d-4632-c398-9e7d1bf8942e"
   },
   "outputs": [],
   "source": [
    " \"Training examples\", BATCH_SIZE * len(detectability_data.train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uEnVWjtRr7qT",
    "outputId": "4a8de4e3-2857-4c6c-d939-c79d72e8313a"
   },
   "outputs": [],
   "source": [
    "\"Validation examples\", BATCH_SIZE * len(detectability_data.val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lzNXJ-s6r7qQ"
   },
   "outputs": [],
   "source": [
    "\"Test examples\", BATCH_SIZE * len(detectability_data.test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to retrieve the different dataset splits as DataFrames by using the `.get_split_dataframe` method and specifying the desired split: `train`, `val`, or `test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_df = detectability_data.get_split_dataframe(split = \"test\")\n",
    "test_data_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oWeVi0iar7qT"
   },
   "source": [
    "## 2. Model\n",
    "\n",
    "We can now create the model. The model architecture is an encoder-decoder with an attention mechanism, that is based on Bidirectional Recurrent Neural Network (BRNN) with Gated Recurrent Units (GRU). Both the Encoder and Decoder consists of a single layer, with the Decoder also including a Dense layer. The model has the default working arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q8SGTvfRr7qT"
   },
   "outputs": [],
   "source": [
    "from dlomix.models import detetability_model\n",
    "from dlomix.detectability_model_constants import CLASSES_LABELS, alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZqrsF6APr7qU"
   },
   "outputs": [],
   "source": [
    "total_num_classes = len(CLASSES_LABELS)\n",
    "input_dimension = len(alphabet)\n",
    "num_cells = 64\n",
    "\n",
    "model = detetability_model.detetability_model(num_units = num_cells,\n",
    "                                              num_clases = total_num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "adD60VwQr7qU"
   },
   "source": [
    "## 3. Training and saving the model\n",
    "\n",
    "You can train the model using the standard Keras approach. The training parameters provided here are those initially configured for the detectability model. However, you have the flexibility to modify these parameters to suit your specific needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile the Model\n",
    "\n",
    "Compile the model with the selected settings. You can use built-in TensorFlow options or define and pass custom settings for the optimizer, loss function, and metrics. The default configurations match those used in the original study, but you can modify these settings according to your preferences.\n",
    "\n",
    "Early stopping is also configured with the original settings, but the parameters can be adjusted based on user preferences. Early stopping monitors a performance metric (e.g., validation loss) and halts training when no improvement is observed for a specified number of epochs. This feature helps prevent overfitting and ensures efficient training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xLy32wk7r7qU",
    "outputId": "34f9961e-1abc-4f8f-904c-7aac4a404241"
   },
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', \n",
    "                                            mode = 'min', \n",
    "                                            verbose = 1, \n",
    "                                            patience = 5)\n",
    "\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath = 'output/weights/new_base_model/base_model_weights',\n",
    "                                                      monitor = 'val_categorical_accuracy',\n",
    "                                                      mode = 'max',\n",
    "                                                      verbose = 1,\n",
    "                                                      save_best_only = True, \n",
    "                                                      save_weights_only = True)\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'CategoricalCrossentropy',\n",
    "              metrics = 'categorical_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wtEUn_vdr7qV"
   },
   "source": [
    "We save the results of the training process to enable a detailed examination of the metrics and losses at a later stage. We define the number of epochs for training and supply the training and validation data previously generated. This approach allows us to effectively monitor the model’s performance and make any necessary adjustments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E14EcoYTr7qV",
    "outputId": "9c88b2d5-e1cb-46b4-e263-73468e222554",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(detectability_data.train_data,\n",
    "                    validation_data = detectability_data.val_data,\n",
    "                    epochs = 50, \n",
    "                    callbacks=[callback, model_checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oukZ4AyMr7qV"
   },
   "source": [
    "## 4. Testing and Reporting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the test dataset to assess our model's performance, which is only applicable if labels are available. The `detectability_report` class allows us to compute various metrics, generate reports, and create plots for a comprehensive evaluation of the model.\n",
    "\n",
    "Note: The reporting module is currently under development, so some features may be unstable or subject to change.\n",
    "\n",
    "In the next cell, set the path to the model weights. By default, it points to the newly trained base model. If using different weights, update the path accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading best model's weights \n",
    "\n",
    "model.load_weights('output/weights/new_base_model/base_model_weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate Predictions on Test Data Using `model.predict`\n",
    "\n",
    "To obtain predictions for your test data, use the Keras `model.predict` method. Simply pass your test dataset to this method, and it will return the model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RrvR8Cl3r7qV"
   },
   "outputs": [],
   "source": [
    "# use model.predict from keras directly on the testdata\n",
    "\n",
    "predictions = model.predict(detectability_data.test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate reports and calculate evaluation metrics against predictions, you need to obtain the targets and DataFrames for the specific dataset split. This can be achieved using the `get_split_targets` and `get_split_dataframe` functions from the `detectability_dataset` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wKk7MD7Wr7qW"
   },
   "outputs": [],
   "source": [
    "test_targets = detectability_data.get_split_targets(split = \"test\")\n",
    "test_data_df = detectability_data.get_split_dataframe(split = \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "4kzCh0gwr7qX"
   },
   "outputs": [],
   "source": [
    "from dlomix.reports.detectability_report import detectability_report, predictions_report\n",
    "WANDB_REPORT_API_DISABLE_MESSAGE=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate a Report Using the `detectability_report` Class\n",
    "\n",
    "The `detectability_report` class provides a comprehensive way to evaluate your model by generating detailed reports and visualizations. The outputs include:\n",
    "\n",
    "1. **A PDF Report**: This includes evaluation metrics and plots.\n",
    "2. **A CSV File**: Contains the model’s predictions.\n",
    "3. **Independent Image Files**: Visualizations are saved as separate image files.\n",
    "\n",
    "To generate a report, provide the following parameters to the `detectability_report` class:\n",
    "\n",
    "- **targets**: The true labels for the dataset, which are used to assess the model’s performance.\n",
    "- **predictions**: The model’s output predictions for the dataset, which will be compared against the true labels.\n",
    "- **input_data_df**: The DataFrame containing the input data used for generating predictions.\n",
    "- **output_path**: The directory path where the generated reports, images, and CSV file will be saved.\n",
    "- **history**: The training history object (e.g., containing metrics from training) if available. Set this to `None` if not applicable, such as when the report is generated for predictions without training.\n",
    "- **rank_by_prot**: A boolean indicating whether to rank peptides based on their associated proteins (`True` or `False`).\n",
    "- **threshold**: The classification threshold used to adjust the decision boundary for predictions. By default, this is set to `None`, meaning no specific threshold is applied.\n",
    "- **name_of_dataset**: The name of the dataset used for generating predictions, which will be included in the report to provide context.\n",
    "- **name_of_model**: The name of the model used to generate the predictions, which will be specified in the report for reference.\n",
    "\n",
    "Note: The reporting module is currently under development, so some features may be unstable or subject to change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_7LJZ3TLr7qX"
   },
   "outputs": [],
   "source": [
    "report = detectability_report(targets = test_targets, \n",
    "                              predictions = predictions, \n",
    "                              input_data_df = test_data_df,\n",
    "                              output_path = \"./output/report_on_ProteomeTools\", \n",
    "                              history = history, \n",
    "                              rank_by_prot = False,\n",
    "                              threshold = None,\n",
    "                              name_of_dataset = 'ProteomeTools',\n",
    "                              name_of_model = 'Base model (new)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = report.detectability_report_table\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating Evaluation Plots with `detectability_report`\n",
    "\n",
    "The `detectability_report` class enables you to generate a range of plots to visualize and evaluate model performance. It offers a comprehensive suite of visualizations to help you interpret the results of your model's predictions. Here’s how to use it:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training and Validation Metrics\n",
    "\n",
    "These plots show the training and validation metrics over epochs. The first plot displays the loss, and the second shows the categorical accuracy. Both plots are generated from the `history` object recorded during the model training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "1iI-_Nufr7qX",
    "outputId": "25baa9f5-1d5b-47ed-d75a-def6a55e43bc"
   },
   "outputs": [],
   "source": [
    "report.plot_keras_metric(\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.plot_keras_metric(\"categorical_accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ROC curve (Binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.plot_roc_curve_binary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion matrix (Binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.plot_confusion_matrix_binary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ROC curve (Multi-class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.plot_roc_curve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion matrix (Multi-class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.plot_confusion_matrix_multiclass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heatmap of Average Error Between Actual and Predicted Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.plot_heatmap_prediction_prob_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also produce a complete report with all the relevant plots in one PDF file by calling the `generate_report` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.generate_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Defining a Classification Threshold\n",
    "\n",
    "In the following example, a specific classification threshold is defined to adjust the decision boundary for the model's predictions. By setting a threshold, you can control the sensitivity of the model, influencing how it categorizes the output into different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_using_threshold = detectability_report(test_targets, \n",
    "                                              predictions, \n",
    "                                              test_data_df, \n",
    "                                              output_path = \"./output/report_on_ProteomeTools_with_threshold\", \n",
    "                                              history = history, \n",
    "                                              rank_by_prot = False,\n",
    "                                              threshold = 0.02,                              \n",
    "                                              name_of_dataset = 'ProteomeTools',\n",
    "                                              name_of_model = 'Base model (new) with threshold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_using_threshold.detectability_report_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating a complete PDF report using the `generate_report` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_using_threshold.generate_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load data for fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For fine-tuning, the process mirrors the steps used during training. Simply create a `detectability_dataset` object with the fine-tuning data (refer to **Section 1: Load Data for Training**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATAPATH = './example_dataset/Sinitcyn_train_data.csv'\n",
    "\n",
    "max_pep_length = 40\n",
    "BATCH_SIZE = 128\n",
    "            \n",
    "fine_tune_data = detectability_dataset(data_source = TRAIN_DATAPATH, \n",
    "                                       protein_data = \"proteins\",\n",
    "                                       split_on_protein = True, \n",
    "                                       seq_length = max_pep_length, \n",
    "                                       batch_size = BATCH_SIZE, \n",
    "                                       val_ratio = 0.1, \n",
    "                                       test_ratio = 0.2, \n",
    "                                       test = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \"Training examples\", BATCH_SIZE * len(fine_tune_data.train_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \"Validation examples\", BATCH_SIZE * len(fine_tune_data.val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Test examples\", BATCH_SIZE * len(fine_tune_data.test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O1uYK1ZWr7qZ"
   },
   "source": [
    "## 6. Fine tuning the model\n",
    "\n",
    "In the next cell, we create the model and load its weights for fine-tuning. By default, the path is set to the weights of the most recently trained base model. To use different weights, update the path to point to your desired model's weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nYVNZBd-r7qZ",
    "outputId": "9f3f72f8-f852-46e3-ce04-bc574e4c2b6f"
   },
   "outputs": [],
   "source": [
    "save_path = \"./output/weights/new_base_model/base_model_weights\"\n",
    "\n",
    "fine_tuned_model = detetability_model.detetability_model(num_units = num_cells,  \n",
    "                                                         num_clases = total_num_classes)\n",
    "\n",
    "fine_tuned_model.load_weights(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile the Model\n",
    "\n",
    "Compile the model with the selected settings. You can use built-in TensorFlow options or define and pass custom settings for the optimizer, loss function, and metrics. The default configurations match those used in the original study, but you can modify these settings according to your preferences.Early stopping is also configured with the original settings, but the parameters can be adjusted based on user preferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model  with the optimizer and the metrics we want to use.\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', \n",
    "                                            mode = 'min', \n",
    "                                            verbose = 1, \n",
    "                                            patience = 5)\n",
    "\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath = 'output/weights/new_fine_tuned_model/fine_tuned_model_weights',\n",
    "                                                      monitor = 'val_categorical_accuracy',\n",
    "                                                      mode = 'max',\n",
    "                                                      verbose = 1,\n",
    "                                                      save_best_only = True, \n",
    "                                                      save_weights_only = True)\n",
    "\n",
    "fine_tuned_model.compile(optimizer = 'adam',\n",
    "                         loss = 'CategoricalCrossentropy',\n",
    "                         metrics = 'categorical_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We store the result of training so that we can explore the metrics and the losses later. We specify the number of epochs for training and pass the training and validation data as previously described."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_fine_tuned = fine_tuned_model.fit(fine_tune_data.train_data,\n",
    "                                          validation_data = fine_tune_data.val_data,\n",
    "                                          epochs = 50, \n",
    "                                          callbacks=[callback, model_checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Testing and Reporting (Fine-Tuned Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, we load the best model weights obtained from fine-tuning. By default, the path points to the most recently fine-tuned model from the previous cell. Update the path if you wish to load different weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading best model's weights \n",
    "\n",
    "fine_tuned_model.load_weights('output/weights/new_fine_tuned_model/fine_tuned_model_weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating predictions on the test data using the fine-tuned model with `model.predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_FT = fine_tuned_model.predict(fine_tune_data.test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtaining the targets and DataFrame for the test dataset using the `get_split_targets` and `get_split_dataframe` functions from the `detectability_dataset` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_targets_FT = fine_tune_data.get_split_targets(split = \"test\")\n",
    "test_data_df_FT = fine_tune_data.get_split_dataframe(split = \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a report object with the test targets, predictions, and history to generate metrics and plots for the fine-tuned model. For more details, refer to Section 4: Testing and Reporting, which provides a detailed description of the same process for the initial or base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_FT = detectability_report(test_targets_FT, \n",
    "                                 predictions_FT, \n",
    "                                 test_data_df_FT, \n",
    "                                 output_path = \"./output/report_on_Sinitcyn (Fine tuned model)\", \n",
    "                                 history = history_fine_tuned, \n",
    "                                 rank_by_prot = False,\n",
    "                                 threshold = None,                              \n",
    "                                 name_of_dataset = 'Sinitcyn test subset',\n",
    "                                 name_of_model = 'Fine tuned model (new)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions report (Fine-tuned model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_FT = report_FT.detectability_report_table\n",
    "results_df_FT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating a complete PDF report using the `generate_report` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_FT.generate_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating the Evaluation Plots for the Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training and Validation Metrics\n",
    "\n",
    "These plots show the training and validation metrics over epochs. The first plot displays the loss, and the second shows the categorical accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_FT.plot_keras_metric(\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_FT.plot_keras_metric(\"categorical_accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ROC curve (Binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_FT.plot_roc_curve_binary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion matrix (Binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_FT.plot_confusion_matrix_binary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ROC curve (Multi-class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_FT.plot_roc_curve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion matrix (Multi-class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_FT.plot_confusion_matrix_multiclass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heatmap of Average Error Between Actual and Predicted Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_FT.plot_heatmap_prediction_prob_error()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Example_RTModel_Walkthrough.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
